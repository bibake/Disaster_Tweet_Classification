{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20-04_NLP_DisasterTweets_BU.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PpWY-UbQvgEB",
        "3iF8EKtOzZRz",
        "hk8ppkmA3wz7",
        "9dTUuZ-DjM27",
        "M4kuXEPJjKUu",
        "5Tsa-LxQjTfo",
        "E1_TdV5bzhn8",
        "3UsFQh0neEzl",
        "KI4ngANweH_t",
        "EisaidhqebZD",
        "W1n4YVxzmT_o",
        "UTQVvQAZW71-",
        "ve0R0nXLXGgR",
        "vmPOYQYkXK5T",
        "YxlfFMATd7Mf",
        "i6DJFmkWiETV",
        "hjNQ6dgATFKt",
        "NiVmxFZLT5tA",
        "ioRl6a2TVbT6",
        "8N69szSDj3kJ",
        "ezXVpBTDn-M9",
        "RcD3vzzEno8n",
        "fQwy8_BN2qTY",
        "LptcEunD2t7K",
        "hd_EFhTNodaR",
        "fEPhDqEb2ODy",
        "1POWfbGvhIzJ",
        "qqjkWZHF2ej8",
        "vXvRn_3I2iKy",
        "UugcJFwndvcZ",
        "CJxwB2Syc6AT",
        "PysJM6qqWWbT",
        "uB-lghhVrCXO",
        "OSt4PbxQiEdR",
        "KtnpQzfnMxB5",
        "z4s7R5ubUJe2",
        "FlSsSUxpeMxW",
        "U_6RusD-wk6F",
        "zJ6ImBo4QV-V",
        "KvElzdL5Y63E",
        "Yo7umDR8sIFz",
        "xxV-r1Nbp7YE",
        "ypu1oQCZvno_",
        "ZrsGW5e0_uz_",
        "TTxcTTsczlQn",
        "ow0Nf84C1GEO",
        "wbr8WPvrj1dk",
        "NRFr5Basx1VH",
        "cPhth2yI5iL_",
        "KyAwhGDB669U",
        "0H5JYvhTx1VJ",
        "JyiMLk7px1VK",
        "wN8XlNnYx1VL",
        "QE81whUCx1VL",
        "PABLeugcxpNC",
        "VE9mj4AWQxHD",
        "YzuFKGteitca",
        "6Cz9eNyfY9Fi",
        "Ag9m6WU57T-I",
        "Yu-c08pSx1D2",
        "td1SQyYQ1R2y",
        "DJd2dJa31YCq",
        "URvYe_He1csE",
        "eQsEIVZw1kss",
        "cP6NFcIH4mxf"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bibake/Disaster_Tweet_Classification/blob/master/20_04_NLP_DisasterTweets_BU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XL39RE9eWvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.exceptions import FitFailedWarning\n",
        "warnings.filterwarnings(\"ignore\", category = DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', category = FitFailedWarning)\n",
        "warnings.filterwarnings('ignore', category = UserWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8V163aLx7Yqj"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpWY-UbQvgEB",
        "colab_type": "text"
      },
      "source": [
        "# 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK0i3Po6ER0H",
        "colab_type": "text"
      },
      "source": [
        "This notebook depicts a comprehensive programming solution to solve the Kaggle text classification challenge described [here](https://www.kaggle.com/c/nlp-getting-started/overview).\n",
        "\n",
        "<br>\n",
        "\n",
        "The task is a supervised binary text classification task of tweets from Twitter. The tweets are classified as either related to a **real disaster** or **not**. The purpose of the task is to establish an algorithm that can automatically and accurately determine if a tweet is referring to a real disaster or not. The applications for this are wide-ranging. Among the main uses is as an **emergency response support tool**. \n",
        "\n",
        "<br>\n",
        "\n",
        "At a high level, this notebook achieves the following:\n",
        "\n",
        "- Understand data\n",
        "- Prepare data\n",
        "- Train classification algorithms\n",
        "- Make predictions on unseen data\n",
        "\n",
        "<br>\n",
        "\n",
        "The notebook is organized in the following sections:<br /><font size=\"2\"> _**Note**: these sections can be navigated using the table of contents found in the left side-bar._\n",
        "\n",
        "1. Introduction\n",
        "2. Load and Explore Data\n",
        "3. Baseline Models\n",
        "4. Further Cleaning and Modelling\n",
        "5. Deep Learning\n",
        "6. Conclusion\n",
        "\n",
        "The main focus of this notebook is on non-deep learning techniques. Thus, only the last portion of the notebook is dedicated to deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6EulOlRv7XVf"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iF8EKtOzZRz",
        "colab_type": "text"
      },
      "source": [
        "# 2. Load and Explore Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hk8ppkmA3wz7"
      },
      "source": [
        "## Load and Basic Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IcKzYKny0-F",
        "colab_type": "text"
      },
      "source": [
        "Algorithms are triained using a labelled dataset provided on Kaggle ([here](https://www.kaggle.com/c/nlp-getting-started/data) and [here](https://gist.githubusercontent.com/bibake/f484cab46630d36bf05faf78fb65a358/raw/95a256cfef101a317115f6d5f0ff5f91ee8e9fc6/train.csv)). Predictions are made on the unlabelled test set ([here](https://www.kaggle.com/c/nlp-getting-started/data) and [here](https://gist.githubusercontent.com/bibake/f484cab46630d36bf05faf78fb65a358/raw/95a256cfef101a317115f6d5f0ff5f91ee8e9fc6/test.csv)).\n",
        "\n",
        "Here we load the two datasets, as well as a submission file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DKTKztVefLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('https://gist.githubusercontent.com/bibake/f484cab46630d36bf05faf78fb65a358/raw/95a256cfef101a317115f6d5f0ff5f91ee8e9fc6/train.csv')\n",
        "test = pd.read_csv('https://gist.githubusercontent.com/bibake/f484cab46630d36bf05faf78fb65a358/raw/95a256cfef101a317115f6d5f0ff5f91ee8e9fc6/test.csv')\n",
        "submission = pd.read_csv('https://gist.githubusercontent.com/bibake/f484cab46630d36bf05faf78fb65a358/raw/d89ae3903e8b24869a5fb58b1cdb79ad5c31f19d/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIf5n2Nuyr_C",
        "colab_type": "text"
      },
      "source": [
        "The datasets, the first 5 lines of which can be seen below, contain the following columns:\n",
        "\n",
        "- **id** - a unique identifier for each tweet\n",
        "- **text** - the text of the tweet\n",
        "- **location** - the location the tweet was sent from (may be blank)\n",
        "- **keyword** - a particular keyword from the tweet (may be blank)\n",
        "- **target** - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDW4bV1SmUS7",
        "colab_type": "code",
        "outputId": "e38ca8a9-9cbc-468f-cf23-f5efb5b84ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "display(train.head(), test.head(), submission.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... target\n",
              "0   1  ...      1\n",
              "1   4  ...      1\n",
              "2   5  ...      1\n",
              "3   6  ...      1\n",
              "4   7  ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                                                                              text\n",
              "0   0  ...                                                                Just happened a terrible car crash\n",
              "1   2  ...                                  Heard about #earthquake is different cities, stay safe everyone.\n",
              "2   3  ...  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all\n",
              "3   9  ...                                                          Apocalypse lighting. #Spokane #wildfires\n",
              "4  11  ...                                                     Typhoon Soudelor kills 28 in China and Taiwan\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  target\n",
              "0   0       0\n",
              "1   2       0\n",
              "2   3       0\n",
              "3   9       0\n",
              "4  11       0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dTUuZ-DjM27",
        "colab_type": "text"
      },
      "source": [
        "### Shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRICtuEZmnf2",
        "colab_type": "code",
        "outputId": "600b2e0e-3e86-4092-e2e9-47f453dd974e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('There are {} rows and {} columns in train'.format(train.shape[0], train.shape[1]))\n",
        "print('There are {} rows and {} columns in train'.format(test.shape[0], test.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 7613 rows and 5 columns in train\n",
            "There are 3263 rows and 4 columns in train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4kuXEPJjKUu",
        "colab_type": "text"
      },
      "source": [
        "### Data-types and NULLs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FD6x74Nm34g",
        "colab_type": "code",
        "outputId": "70d8ab63-0b60-4b90-91f8-33f5372a4510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print(train.info())\n",
        "print('\\n', train.isna().sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7613 entries, 0 to 7612\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        7613 non-null   int64 \n",
            " 1   keyword   7552 non-null   object\n",
            " 2   location  5080 non-null   object\n",
            " 3   text      7613 non-null   object\n",
            " 4   target    7613 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 297.5+ KB\n",
            "None\n",
            "\n",
            " id             0\n",
            "keyword       61\n",
            "location    2533\n",
            "text           0\n",
            "target         0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMv5a5Yai4hX",
        "colab_type": "text"
      },
      "source": [
        "We see from the output above that there are two numeric columns and three categorical. Of the five, two have missing values, keyword and location."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Tsa-LxQjTfo",
        "colab_type": "text"
      },
      "source": [
        "### Class balance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tWyoJLpnAze",
        "colab_type": "code",
        "outputId": "5e69bdd5-8ded-41ee-d9df-492195d7234f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train.target.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p80WF293nGB-",
        "colab_type": "code",
        "outputId": "dce2121e-4ca1-4a4b-c3d3-18c3dbc33c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.style.use('fast')\n",
        "\n",
        "sns.barplot(train.target.value_counts().index, train.target.value_counts().values, alpha=0.5, palette=[\"green\", 'red'])\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.xlabel('Target', fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2ujQQ_2j7VF4"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPbwnFKijZml",
        "colab_type": "text"
      },
      "source": [
        "Wee see that there is a slight imbalance in favor of beinign (non-disaster) tweets. The imbalance, however, is not so large that it will significantly effect our modelling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1_TdV5bzhn8",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UsFQh0neEzl",
        "colab_type": "text"
      },
      "source": [
        "#### Characters per tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5ec071d8-4b55-4fa6-b241-02949a25c9d0",
        "id": "R2pahRaydPmR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
        "tweet_len=train[train['target']==0]['text'].str.len()\n",
        "ax1.hist(tweet_len,color='green', alpha = 0.5)\n",
        "ax1.set_title('Benign tweets')\n",
        "tweet_len=train[train['target']==1]['text'].str.len()\n",
        "ax2.hist(tweet_len,color='red', alpha = 0.5)\n",
        "ax2.set_title('Disaster tweets')\n",
        "fig.suptitle('Characters in tweets')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI4ngANweH_t",
        "colab_type": "text"
      },
      "source": [
        "#### Words per tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLfXjBL-eKzR",
        "colab_type": "code",
        "outputId": "000a64a0-ce19-4069-eff6-59277f00a7ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
        "tweet_len=train[train['target']==0]['text'].str.split().map(lambda x: len(x))\n",
        "ax1.hist(tweet_len,color='green', alpha = 0.5)\n",
        "ax1.set_title('Benign tweets')\n",
        "tweet_len=train[train['target']==1]['text'].str.split().map(lambda x: len(x))\n",
        "ax2.hist(tweet_len,color='red', alpha = 0.5)\n",
        "ax2.set_title('Disaster tweets')\n",
        "fig.suptitle('Words in a tweet')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EisaidhqebZD",
        "colab_type": "text"
      },
      "source": [
        "#### Average word length per tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV6kBlO9eeGv",
        "colab_type": "code",
        "outputId": "f46e1b88-87af-4820-a56a-f0abe971c197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
        "word=train[train['target']==0]['text'].str.split().apply(lambda x : [len(i) for i in x])\n",
        "sns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='green')\n",
        "ax1.set_title('Benign')\n",
        "word=train[train['target']==1]['text'].str.split().apply(lambda x : [len(i) for i in x])\n",
        "sns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='red')\n",
        "ax2.set_title('Disaster')\n",
        "fig.suptitle('Average word length in each tweet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0.98, 'Average word length in each tweet')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1n4YVxzmT_o",
        "colab_type": "text"
      },
      "source": [
        "#### N-Gram analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX4KEhp7mWTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/shahules/basic-eda-cleaning-and-glove\n",
        "\n",
        "def get_top_tweet_bigrams(corpus, n=None):\n",
        "    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--UvQYobmaKy",
        "colab_type": "code",
        "outputId": "8c184d61-425e-4e0f-91b7-5078b968abbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "top_tweet_bigrams = get_top_tweet_bigrams(train['text'])[:10]\n",
        "x,y=map(list,zip(*top_tweet_bigrams))\n",
        "sns.barplot(x=y,y=x, alpha = 0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f52a4f7b518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWUaHrK97ROu",
        "colab_type": "text"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTQVvQAZW71-",
        "colab_type": "text"
      },
      "source": [
        "## Identifying and Treating Discrepancies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve0R0nXLXGgR",
        "colab_type": "text"
      },
      "source": [
        "### Mis-labelled tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcAd_hUu1kZU",
        "colab_type": "text"
      },
      "source": [
        "Here, I draw from the work done [here](https://www.kaggle.com/muhammedfathi/fake-or-real-with-bert) to identify and relabel tweets that have erroneously been labeled as disasters.\n",
        "\n",
        "This step is important to ensure that our model is not learning patterns from incorrect data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPXGSOClV75t",
        "colab_type": "code",
        "outputId": "81059782-f318-4218-d708-c45ab2cb949a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "ids_with_target_error = [328,443,513,2619,3640,3900,4342,5781,6552,6554,6570,6701,6702,6729,6861,7226]\n",
        "train[train['id'].isin(ids_with_target_error)][['text', 'target']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>Ready to get annihilated for the BUCS game</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>Short Reading\\n\\nApocalypse 21:1023 \\n\\nIn the spirit the angel took me to the top of an enormous high mountain and... http://t.co/v8AfTD9zeZ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>But if you build an army of 100 dogs and their leader is a lion all dogs will fight like a lion.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1822</th>\n",
              "      <td>My iPod crashed..... \\n#WeLoveYouLouis \\n#MTVHottest One Direction</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2536</th>\n",
              "      <td>This desperation dislocation\\nSeparation condemnation\\nRevelation in temptation\\nIsolation desolation\\nLet it go and so to find away</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2715</th>\n",
              "      <td>Man Currensy really be talkin that talk... I'd be more devastated if he had a ghostwriter than anybody else....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3024</th>\n",
              "      <td>Going to a fest? Bring swimming goggles for the dust storm in the circle pit</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4068</th>\n",
              "      <td>Campsite recommendations \\nToilets /shower \\nPub \\nFires \\nNo kids \\nPizza shop \\nForest \\nPretty stream \\nNo midges\\nNo snakes\\nThanks ??</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4609</th>\n",
              "      <td>My prediction for the Vikings game this Sunday....dont expect a whole lot. Infact I think Zimmer goal is....injury free 1st game</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4611</th>\n",
              "      <td>Dante Exum's knee injury could stem Jazz's hoped-for surge back to ... http://t.co/8PIFutrB5U</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4622</th>\n",
              "      <td>@Sport_EN Just being linked to Arsenal causes injury.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4713</th>\n",
              "      <td>Imagine a room with walls that are lava lamps.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4714</th>\n",
              "      <td>The sunset looked like an erupting volcano .... My initial thought was the Pixar short Lava http://t.co/g4sChqFEsT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4732</th>\n",
              "      <td>Check out my Lava lamp dude ???? http://t.co/To9ViqooFv</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4820</th>\n",
              "      <td>If abortion is murder then blowjobs are cannibalism and masturbation is mass genocide.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5068</th>\n",
              "      <td>Of course the one day I have to dress professionally aka unsensibly for class is the day I have try and outrun a natural disaster!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                               text  target\n",
              "229                                                                                                      Ready to get annihilated for the BUCS game       1\n",
              "301   Short Reading\\n\\nApocalypse 21:1023 \\n\\nIn the spirit the angel took me to the top of an enormous high mountain and... http://t.co/v8AfTD9zeZ       1\n",
              "356                                                But if you build an army of 100 dogs and their leader is a lion all dogs will fight like a lion.       1\n",
              "1822                                                                             My iPod crashed..... \\n#WeLoveYouLouis \\n#MTVHottest One Direction       1\n",
              "2536           This desperation dislocation\\nSeparation condemnation\\nRevelation in temptation\\nIsolation desolation\\nLet it go and so to find away       1\n",
              "2715                                Man Currensy really be talkin that talk... I'd be more devastated if he had a ghostwriter than anybody else....       1\n",
              "3024                                                                   Going to a fest? Bring swimming goggles for the dust storm in the circle pit       1\n",
              "4068     Campsite recommendations \\nToilets /shower \\nPub \\nFires \\nNo kids \\nPizza shop \\nForest \\nPretty stream \\nNo midges\\nNo snakes\\nThanks ??       1\n",
              "4609               My prediction for the Vikings game this Sunday....dont expect a whole lot. Infact I think Zimmer goal is....injury free 1st game       1\n",
              "4611                                                  Dante Exum's knee injury could stem Jazz's hoped-for surge back to ... http://t.co/8PIFutrB5U       1\n",
              "4622                                                                                          @Sport_EN Just being linked to Arsenal causes injury.       1\n",
              "4713                                                                                                 Imagine a room with walls that are lava lamps.       1\n",
              "4714                             The sunset looked like an erupting volcano .... My initial thought was the Pixar short Lava http://t.co/g4sChqFEsT       1\n",
              "4732                                                                                        Check out my Lava lamp dude ???? http://t.co/To9ViqooFv       1\n",
              "4820                                                         If abortion is murder then blowjobs are cannibalism and masturbation is mass genocide.       1\n",
              "5068             Of course the one day I have to dress professionally aka unsensibly for class is the day I have try and outrun a natural disaster!       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDCOh0F32Rp4",
        "colab_type": "text"
      },
      "source": [
        "Having identified the mis-labelled tweets, the code below re-labels them as 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxiv4cAjC8nX",
        "colab_type": "code",
        "outputId": "6d04104c-85b1-4d75-c17b-10b3dadc43c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "train.at[train['id'].isin(ids_with_target_error),'target'] = 0\n",
        "train[train['id'].isin(ids_with_target_error)][['text', 'target']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>Ready to get annihilated for the BUCS game</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>Short Reading\\n\\nApocalypse 21:1023 \\n\\nIn the spirit the angel took me to the top of an enormous high mountain and... http://t.co/v8AfTD9zeZ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>But if you build an army of 100 dogs and their leader is a lion all dogs will fight like a lion.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1822</th>\n",
              "      <td>My iPod crashed..... \\n#WeLoveYouLouis \\n#MTVHottest One Direction</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2536</th>\n",
              "      <td>This desperation dislocation\\nSeparation condemnation\\nRevelation in temptation\\nIsolation desolation\\nLet it go and so to find away</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2715</th>\n",
              "      <td>Man Currensy really be talkin that talk... I'd be more devastated if he had a ghostwriter than anybody else....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3024</th>\n",
              "      <td>Going to a fest? Bring swimming goggles for the dust storm in the circle pit</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4068</th>\n",
              "      <td>Campsite recommendations \\nToilets /shower \\nPub \\nFires \\nNo kids \\nPizza shop \\nForest \\nPretty stream \\nNo midges\\nNo snakes\\nThanks ??</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4609</th>\n",
              "      <td>My prediction for the Vikings game this Sunday....dont expect a whole lot. Infact I think Zimmer goal is....injury free 1st game</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4611</th>\n",
              "      <td>Dante Exum's knee injury could stem Jazz's hoped-for surge back to ... http://t.co/8PIFutrB5U</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4622</th>\n",
              "      <td>@Sport_EN Just being linked to Arsenal causes injury.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4713</th>\n",
              "      <td>Imagine a room with walls that are lava lamps.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4714</th>\n",
              "      <td>The sunset looked like an erupting volcano .... My initial thought was the Pixar short Lava http://t.co/g4sChqFEsT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4732</th>\n",
              "      <td>Check out my Lava lamp dude ???? http://t.co/To9ViqooFv</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4820</th>\n",
              "      <td>If abortion is murder then blowjobs are cannibalism and masturbation is mass genocide.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5068</th>\n",
              "      <td>Of course the one day I have to dress professionally aka unsensibly for class is the day I have try and outrun a natural disaster!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                               text  target\n",
              "229                                                                                                      Ready to get annihilated for the BUCS game       0\n",
              "301   Short Reading\\n\\nApocalypse 21:1023 \\n\\nIn the spirit the angel took me to the top of an enormous high mountain and... http://t.co/v8AfTD9zeZ       0\n",
              "356                                                But if you build an army of 100 dogs and their leader is a lion all dogs will fight like a lion.       0\n",
              "1822                                                                             My iPod crashed..... \\n#WeLoveYouLouis \\n#MTVHottest One Direction       0\n",
              "2536           This desperation dislocation\\nSeparation condemnation\\nRevelation in temptation\\nIsolation desolation\\nLet it go and so to find away       0\n",
              "2715                                Man Currensy really be talkin that talk... I'd be more devastated if he had a ghostwriter than anybody else....       0\n",
              "3024                                                                   Going to a fest? Bring swimming goggles for the dust storm in the circle pit       0\n",
              "4068     Campsite recommendations \\nToilets /shower \\nPub \\nFires \\nNo kids \\nPizza shop \\nForest \\nPretty stream \\nNo midges\\nNo snakes\\nThanks ??       0\n",
              "4609               My prediction for the Vikings game this Sunday....dont expect a whole lot. Infact I think Zimmer goal is....injury free 1st game       0\n",
              "4611                                                  Dante Exum's knee injury could stem Jazz's hoped-for surge back to ... http://t.co/8PIFutrB5U       0\n",
              "4622                                                                                          @Sport_EN Just being linked to Arsenal causes injury.       0\n",
              "4713                                                                                                 Imagine a room with walls that are lava lamps.       0\n",
              "4714                             The sunset looked like an erupting volcano .... My initial thought was the Pixar short Lava http://t.co/g4sChqFEsT       0\n",
              "4732                                                                                        Check out my Lava lamp dude ???? http://t.co/To9ViqooFv       0\n",
              "4820                                                         If abortion is murder then blowjobs are cannibalism and masturbation is mass genocide.       0\n",
              "5068             Of course the one day I have to dress professionally aka unsensibly for class is the day I have try and outrun a natural disaster!       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmPOYQYkXK5T",
        "colab_type": "text"
      },
      "source": [
        "### Semantically identical tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckP7uuhS2YOm",
        "colab_type": "text"
      },
      "source": [
        "In addition to mis-labelled tweets, there are duplicated tweets, many of which have inconsistent labels. This draws from the work done [here](https://www.kaggle.com/dmitri9149/transformer-svm-semantically-identical-tweets). Rather than merely ensuring consistency among duplicate tweets, I will find all duplicates, regardless of label consistency, and remove all but one. To do this, I define some helper functions based on code found [here](https://www.quora.com/How-do-I-calculate-Cosine-Similarity-between-tweets)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxlfFMATd7Mf",
        "colab_type": "text"
      },
      "source": [
        "#### Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zY2f8Vi3DDr",
        "colab_type": "text"
      },
      "source": [
        "The first helper function serves to create a dictionary from the text passed. The dictionary keys are the words in the text and the values are the frequency of those words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEVFnVx3ZoR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re, math\n",
        "from collections import Counter\n",
        "\n",
        "WORD = re.compile(r'\\w+')\n",
        "\n",
        "def iNeedAVector(text):\n",
        "     words = WORD.findall(text)\n",
        "     return Counter(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMRY89L03xPJ",
        "colab_type": "text"
      },
      "source": [
        "Using the iNeedAVector function, I create a new column in the training dataframe that contains the corresponding dictionary for each tweet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFhj5mBF3vnl",
        "colab_type": "code",
        "outputId": "5cec6db3-8690-48f1-f59e-17c6320d2b2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train['vector'] = train['text'].map(lambda x: iNeedAVector(x))\n",
        "train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
              "      <td>1</td>\n",
              "      <td>{'Our': 1, 'Deeds': 1, 'are': 1, 'the': 1, 'Reason': 1, 'of': 1, 'this': 1, 'earthquake': 1, 'May': 1, 'ALLAH': 1, 'Forgive': 1, 'us': 1, 'all': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>{'Forest': 1, 'fire': 1, 'near': 1, 'La': 1, 'Ronge': 1, 'Sask': 1, 'Canada': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
              "      <td>1</td>\n",
              "      <td>{'All': 1, 'residents': 1, 'asked': 1, 'to': 1, 'shelter': 2, 'in': 2, 'place': 2, 'are': 2, 'being': 1, 'notified': 1, 'by': 1, 'officers': 1, 'No': 1, 'other': 1, 'evacuation': 1, 'or': 1, 'orders': 1, 'expected': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
              "      <td>1</td>\n",
              "      <td>{'13': 1, '000': 1, 'people': 1, 'receive': 1, 'wildfires': 1, 'evacuation': 1, 'orders': 1, 'in': 1, 'California': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
              "      <td>1</td>\n",
              "      <td>{'Just': 1, 'got': 1, 'sent': 1, 'this': 1, 'photo': 1, 'from': 2, 'Ruby': 1, 'Alaska': 1, 'as': 1, 'smoke': 1, 'wildfires': 1, 'pours': 1, 'into': 1, 'a': 1, 'school': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>10869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5</td>\n",
              "      <td>1</td>\n",
              "      <td>{'Two': 1, 'giant': 1, 'cranes': 1, 'holding': 1, 'a': 1, 'bridge': 1, 'collapse': 1, 'into': 1, 'nearby': 1, 'homes': 1, 'http': 1, 't': 1, 'co': 1, 'STfMbbZFB5': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>10870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.</td>\n",
              "      <td>1</td>\n",
              "      <td>{'aria_ahrary': 1, 'TheTawniest': 1, 'The': 1, 'out': 1, 'of': 2, 'control': 1, 'wild': 1, 'fires': 1, 'in': 2, 'California': 1, 'even': 1, 'the': 2, 'Northern': 1, 'part': 1, 'state': 1, 'Very': 1, 'troubling': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>10871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ</td>\n",
              "      <td>1</td>\n",
              "      <td>{'M1': 1, '94': 1, '01': 1, '04': 1, 'UTC': 1, '5km': 1, 'S': 1, 'of': 1, 'Volcano': 1, 'Hawaii': 1, 'http': 1, 't': 1, 'co': 1, 'zDtoyd8EbJ': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>10872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.</td>\n",
              "      <td>1</td>\n",
              "      <td>{'Police': 1, 'investigating': 1, 'after': 1, 'an': 1, 'e': 1, 'bike': 2, 'collided': 1, 'with': 1, 'a': 1, 'car': 1, 'in': 1, 'Little': 1, 'Portugal': 1, 'E': 1, 'rider': 1, 'suffered': 1, 'serious': 1, 'non': 1, 'life': 1, 'threatening': 1, 'injuries': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>10873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d</td>\n",
              "      <td>1</td>\n",
              "      <td>{'The': 1, 'Latest': 1, 'More': 1, 'Homes': 1, 'Razed': 1, 'by': 1, 'Northern': 1, 'California': 1, 'Wildfire': 1, 'ABC': 1, 'News': 1, 'http': 1, 't': 1, 'co': 1, 'YmY4rSkQ3d': 1}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows  6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ...                                                                                                                                                                                                                                                             vector\n",
              "0         1  ...                                                                                                                {'Our': 1, 'Deeds': 1, 'are': 1, 'the': 1, 'Reason': 1, 'of': 1, 'this': 1, 'earthquake': 1, 'May': 1, 'ALLAH': 1, 'Forgive': 1, 'us': 1, 'all': 1}\n",
              "1         4  ...                                                                                                                                                                                   {'Forest': 1, 'fire': 1, 'near': 1, 'La': 1, 'Ronge': 1, 'Sask': 1, 'Canada': 1}\n",
              "2         5  ...                                         {'All': 1, 'residents': 1, 'asked': 1, 'to': 1, 'shelter': 2, 'in': 2, 'place': 2, 'are': 2, 'being': 1, 'notified': 1, 'by': 1, 'officers': 1, 'No': 1, 'other': 1, 'evacuation': 1, 'or': 1, 'orders': 1, 'expected': 1}\n",
              "3         6  ...                                                                                                                                             {'13': 1, '000': 1, 'people': 1, 'receive': 1, 'wildfires': 1, 'evacuation': 1, 'orders': 1, 'in': 1, 'California': 1}\n",
              "4         7  ...                                                                                        {'Just': 1, 'got': 1, 'sent': 1, 'this': 1, 'photo': 1, 'from': 2, 'Ruby': 1, 'Alaska': 1, 'as': 1, 'smoke': 1, 'wildfires': 1, 'pours': 1, 'into': 1, 'a': 1, 'school': 1}\n",
              "...     ...  ...                                                                                                                                                                                                                                                                ...\n",
              "7608  10869  ...                                                                                             {'Two': 1, 'giant': 1, 'cranes': 1, 'holding': 1, 'a': 1, 'bridge': 1, 'collapse': 1, 'into': 1, 'nearby': 1, 'homes': 1, 'http': 1, 't': 1, 'co': 1, 'STfMbbZFB5': 1}\n",
              "7609  10870  ...                                             {'aria_ahrary': 1, 'TheTawniest': 1, 'The': 1, 'out': 1, 'of': 2, 'control': 1, 'wild': 1, 'fires': 1, 'in': 2, 'California': 1, 'even': 1, 'the': 2, 'Northern': 1, 'part': 1, 'state': 1, 'Very': 1, 'troubling': 1}\n",
              "7610  10871  ...                                                                                                                  {'M1': 1, '94': 1, '01': 1, '04': 1, 'UTC': 1, '5km': 1, 'S': 1, 'of': 1, 'Volcano': 1, 'Hawaii': 1, 'http': 1, 't': 1, 'co': 1, 'zDtoyd8EbJ': 1}\n",
              "7611  10872  ...  {'Police': 1, 'investigating': 1, 'after': 1, 'an': 1, 'e': 1, 'bike': 2, 'collided': 1, 'with': 1, 'a': 1, 'car': 1, 'in': 1, 'Little': 1, 'Portugal': 1, 'E': 1, 'rider': 1, 'suffered': 1, 'serious': 1, 'non': 1, 'life': 1, 'threatening': 1, 'injuries': 1}\n",
              "7612  10873  ...                                                                               {'The': 1, 'Latest': 1, 'More': 1, 'Homes': 1, 'Razed': 1, 'by': 1, 'Northern': 1, 'California': 1, 'Wildfire': 1, 'ABC': 1, 'News': 1, 'http': 1, 't': 1, 'co': 1, 'YmY4rSkQ3d': 1}\n",
              "\n",
              "[7613 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09sD0KDJ4PuN",
        "colab_type": "text"
      },
      "source": [
        "With the newly created column, I can compute the cosine similarity between pairs of tweets using the function below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cRUJ_Ct3EXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iNeedACosine(v1, v2):\n",
        "     intersection = set(v1.keys()) & set(v2.keys())\n",
        "     nume = sum([v1[x] * v2[x] for x in intersection])\n",
        "     test1 = sum([v1[x]**2 for x in v1.keys()])\n",
        "     test2 = sum([v2[x]**2 for x in v2.keys()])\n",
        "     den = math.sqrt(test1) * math.sqrt(test2)\n",
        "     if not den:\n",
        "        return 0.0\n",
        "     else:\n",
        "        return float(nume) / den"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSsKvor544SD",
        "colab_type": "text"
      },
      "source": [
        "Cosine similarity measures the cosine angle between tow vectors projected in multi-dimensional space. This is a better measure of similarity than Euclidean distance, because it can identify similarity among documents of different sizes. The smaller the angle, the higher cosine similarity.\n",
        "\n",
        "<br>\n",
        "\n",
        "With the newly defined functions, I loop over each of the tweets in the train set and calculate the cosine similarity with all other tweets. Tweets with cosine similarity greater than 90% are stored in a dictionary (`similar`) with the following structure:\n",
        "\n",
        "- **Keys**: Base tweet\n",
        "- **Values**: Array of tweets with cosine similarty above 90% with the base tweet.\n",
        "\n",
        "<br>\n",
        "\n",
        "Tweets that have been captured as values for a base tweet are stored in an array (`tested`), preventing them from being looped over again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6DJFmkWiETV",
        "colab_type": "text"
      },
      "source": [
        "#### Searching for similar tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzx9sjrDfGy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "similar = defaultdict(list)\n",
        "tested = []\n",
        "\n",
        "for i in range(len(train)):\n",
        "  if i not in tested:\n",
        "    for j in range(len(train)):\n",
        "      if j > i and j not in tested:\n",
        "        sim = iNeedACosine(train['vector'][i], train['vector'][j])\n",
        "        if sim > 0.9:\n",
        "          tested.append(j)\n",
        "          similar[i].append(j)\n",
        "  # if i in similar.keys():\n",
        "  #   print(i, similar[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUuH4i2WDerQ",
        "colab_type": "text"
      },
      "source": [
        "Before continuing, I create a dictionary for similar tweets in the test set as well. These may be useful later on, if there are descrepancies in predicted labels for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cmB8hV1DvL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['vector'] = test['text'].map(lambda x: iNeedAVector(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiqBKfXkDjw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "similar_test = defaultdict(list)\n",
        "tested = []\n",
        "\n",
        "for i in range(len(test)):\n",
        "  if i not in tested:\n",
        "    for j in range(len(test)):\n",
        "      if j > i and j not in tested:\n",
        "        sim = iNeedACosine(test['vector'][i], test['vector'][j])\n",
        "        if sim > 0.9:\n",
        "          tested.append(j)\n",
        "          similar_test[i].append(j)\n",
        "  # if i in similar_test.keys():\n",
        "  #   print(i, similar_test[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4ewlW7gSiLS",
        "colab_type": "text"
      },
      "source": [
        "To avoid having to run the loops above repeatedly, the objects, `similar` and `similar_test`, are saved using `pickle` with the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4I0JB0rURnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('similar_tweets.pkl', 'wb') as f:\n",
        "    pickle.dump([similar, similar_test], f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH8ezwEtS2g7",
        "colab_type": "text"
      },
      "source": [
        "With the objects saved, we can simply load them when needed using the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CCFjQwnUr56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('similar_tweets.pkl', 'rb') as f:\n",
        "    similar, similar_test = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjNQ6dgATFKt",
        "colab_type": "text"
      },
      "source": [
        "#### Exploring similar tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmz0PMieyV8T",
        "colab_type": "code",
        "outputId": "74cffde2-2612-4514-abc7-5775c4a34726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('{} duplicated tweets in the train set.'.format(len(similar)))\n",
        "print('{} duplicate tweets in the test set.'.format(len(similar_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "342 duplicated tweets in the train set.\n",
            "113 duplicate tweets in the test set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwCdW5kO1DiD",
        "colab_type": "text"
      },
      "source": [
        "As we see, there are many tweets that are very similar. Some of these tweets have inconsitent labels. See the example below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "459c60e5-6ddc-4810-c5fe-247020962568",
        "id": "_XIBgBFTBCiR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        }
      },
      "source": [
        "similar_group = [4391, 4392, 4393, 4394, 4396, 4397, 4399, 4400, 4403, 4404, 4405, 4407, 4408, 4412, 4414, 4415, 4420]\n",
        "train.loc[similar_group,['text','target']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4391</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/gUJNPLJVvt #prebreak #best</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4392</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/J2aQs5loxu #prebreak #best</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4393</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/s4PNIhJQX7 #prebreak #best</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4394</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/cx6auPneMu #prebreak #best</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4396</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/wvTPuRYx63 #prebreak #best</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4397</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/J5onxFwLAo #prebreak #best</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4399</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/nQiObcZKrT #prebreak #best</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4400</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/aAtt5aMnmD #prebreak #best</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4403</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/qj3PVgaVN7 #prebreak #best</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4404</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/6AqrNanKFD #prebreak #best</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4405</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/8JcYXhq1AZ #prebreak #best</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4407</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/gexHzU1VK8 #prebreak #best</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4408</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/MIs0RjxuIr #prebreak #best</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4412</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/G62txymzBv #prebreak #best</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4414</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/cOMuiOk3mP #prebreak #best</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4415</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/xV3D9bPjHi #prebreak #best</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4420</th>\n",
              "      <td>#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/UMgD92wLjA #prebreak #best</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                         text  target\n",
              "4391  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/gUJNPLJVvt #prebreak #best       0\n",
              "4392  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/J2aQs5loxu #prebreak #best       1\n",
              "4393  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/s4PNIhJQX7 #prebreak #best       0\n",
              "4394  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/cx6auPneMu #prebreak #best       0\n",
              "4396  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/wvTPuRYx63 #prebreak #best       0\n",
              "4397  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/J5onxFwLAo #prebreak #best       0\n",
              "4399  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/nQiObcZKrT #prebreak #best       0\n",
              "4400  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/aAtt5aMnmD #prebreak #best       0\n",
              "4403  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/qj3PVgaVN7 #prebreak #best       1\n",
              "4404  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/6AqrNanKFD #prebreak #best       0\n",
              "4405  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/8JcYXhq1AZ #prebreak #best       0\n",
              "4407  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/gexHzU1VK8 #prebreak #best       0\n",
              "4408  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/MIs0RjxuIr #prebreak #best       0\n",
              "4412  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/G62txymzBv #prebreak #best       0\n",
              "4414  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/cOMuiOk3mP #prebreak #best       1\n",
              "4415  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/xV3D9bPjHi #prebreak #best       1\n",
              "4420  #hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/UMgD92wLjA #prebreak #best       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuQUkx2w1NV1",
        "colab_type": "text"
      },
      "source": [
        "We will deal with duplicate tweets by removing all but one and assigning 1 or 0, according to which side of 0.5 the mean of the labels is on. For example, the 17 dupicates above only have five '1' labels. Therefore, the mean is close to zero and a zero label will be assigned. This is appropriate given the tweet's content.\n",
        "\n",
        "<br>\n",
        "\n",
        "For tweets that are split, 50/50, I will manually label them, if there aren't too many. If there are too many, I could assign them a default value or a random value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiVmxFZLT5tA",
        "colab_type": "text"
      },
      "source": [
        "#### Treating duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9KDVRncT8EM",
        "colab_type": "text"
      },
      "source": [
        "The length of the train set prior to dealing with duplicates is printed here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPpuqss-BqRy",
        "colab_type": "code",
        "outputId": "ae2b83ff-ba4c-419d-a05b-d39c87a67cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94pFnwReUBD3",
        "colab_type": "text"
      },
      "source": [
        "The code below serves to take the mean label value of all duplicate tweets and assign new values for the base tweets. Following this, non-base tweets are removed. Target values are assigned according to the following scheme:\n",
        "\n",
        "- **1** - mean label of duplicates is _above_ 0.5\n",
        "- **0** - mean label of duplicates is _below_ 0.5\n",
        "- **0.5** - mean label of duplicates _equal_ 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzTDUHiV5RCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for k in similar.keys():\n",
        "  summation = train.loc[similar[k],:]['target'].sum() + train.loc[k,:]['target']\n",
        "  count = len(similar[k]) + 1\n",
        "  mean = summation/count\n",
        "  if mean > 0.5:\n",
        "    train.loc[k,'target'] = 1\n",
        "  elif mean < 0.5:\n",
        "    train.loc[k,'target'] = 0\n",
        "  else:\n",
        "    train.loc[k,'target'] = 0.5\n",
        "  train = train.drop(similar[k])\n",
        "\n",
        "train = train.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOyHS4W3Utzr",
        "colab_type": "text"
      },
      "source": [
        "The new length of the train set can be seen below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbDcKY0WGcRl",
        "colab_type": "code",
        "outputId": "1ea6526b-1134-4675-a89b-8502a33aeccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioRl6a2TVbT6",
        "colab_type": "text"
      },
      "source": [
        "#### Manually assigning labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGvF_K9-UzFw",
        "colab_type": "text"
      },
      "source": [
        "Below is printed the number of tweets that have been labelled `0.5`, corresponding to split vote among duplicated tweets regarding which label to assign."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7bz8FxRACoa",
        "colab_type": "code",
        "outputId": "5f44f666-419c-4c5d-c741-143c5adfed30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train[train['target'] == 0.5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anhx6_sBGeSS",
        "colab_type": "text"
      },
      "source": [
        "We see that 40 tweets were assigned 0.5, because the vote was split. This is a relatively low number. Proper labels can be assigned manually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUlk0Z3gHL84",
        "colab_type": "code",
        "outputId": "58a4b7e2-e95e-4080-9000-8cb7db08f2e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "print(train[train['target'] == 0.5][['text']])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                                                                                                                      text\n",
            "224                            World Annihilation vs Self Transformation http://t.co/pyehwodWun Aliens Attack to Exterminate Humans http://t.co/pB2N77nSKz\n",
            "471                         STAR WARS POWER OF THE JEDI COLLECTION 1 BATTLE DROID HASBRO - Full read by eBay http://t.co/xFguklrlTf http://t.co/FeGu8hWMc4\n",
            "509                                             #world FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps  http://t.co/wvExJjRG6E\n",
            "525                                                                                                                             To fight bioterrorism sir.\n",
            "1054            Ashes 2015: Australias collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/985DwWPdEt\n",
            "1079                                                                  Mmmmmm I'm burning.... I'm burning buildings I'm building.... Oooooohhhh oooh ooh...\n",
            "1096                                                                    I Pledge Allegiance To The P.O.P.E. And The Burning Buildings of Epic City. ??????\n",
            "1103                         like for the music video I want some real action shit like burning buildings and police chases not some weak ben winston shit\n",
            "1112                            Fire hazard associated with installation of non-compliant external cladding on http://t.co/bTPQdehl3p - By @www.cbplawyers\n",
            "1947                                                   Ted Cruz Bashes Obama Comparison GOP To Iranians Shouting 'Death To America' http://t.co/cuFGVupKzi\n",
            "1971                 Bigamist and his 'first' wife are charged in the deaths of his 'second' pregnant wife her child 8 her... http://t.co/dlAub2nVtN #news\n",
            "2076                                                 Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "2292                  @binellithresa TY for the follow Go To http://t.co/UAN05TNkSW BRUTALLY ABUSED+DESOLATE&amp;LOST + HER LOVELY MUM DIES..Is it Murder?\n",
            "2442                                                                                             Apollo Brown ft. M.O.P- Detonate - http://t.co/OMfGv9ma1W\n",
            "2445                                                                                        Detonate (feat. M.O.P.) by Apollo Brown http://t.co/fllaBzGCRc\n",
            "2656                                                                                       @cameronhigdon34 I can't drown my demons they know how to swim.\n",
            "2807                                                                                                                               Earthquake drill ??????\n",
            "2880           Survival Kit Whistle Fire Starter Wire Saw Cree Torch Emergency Blanket S knife  - Full re_ http://t.co/cm7HqwWUlZ http://t.co/KdwAzHQTov\n",
            "3319                                                           Las Vegas in top 5 cities for red-light running fatalities - News3LV http://t.co/eXdbcx4gCR\n",
            "3372                                                     Kosciusko police investigating pedestrian fatality hit by a train Thursday http://t.co/JILfbR0UfP\n",
            "3698                                                    How is it one careless match can start a forest fire but it takes a whole box to start a campfire?\n",
            "3849                                                                          Choking Hazard Prompts Recall Of Kraft Cheese Singles http://t.co/nJLqRqcnL9\n",
            "3897                                                                                                   Caution: breathing may be hazardous to your health.\n",
            "4008                                               Governor weighs parole for California school bus hijacker http://t.co/7NPBfRzEJL http://t.co/Y0kByy8nce\n",
            "4009                                                        RT NotExplained: The only known image of infamous hijacker D.B. Cooper. http://t.co/JlzK2HdeTG\n",
            "4341                           World War II book LIGHTNING JOE An Autobiography by General J. Lawton Collins http://t.co/BzdfznKvoG http://t.co/eRhdH37rDh\n",
            "4475                                                               I liked a @YouTube video from @itsjustinstuart http://t.co/oDV3RqS8JU GUN RANGE MAYHEM!\n",
            "4816                                     Pandemonium In Aba As Woman Delivers Baby Without Face (Photos).... http://t.co/lYXNjlxL8s http://t.co/CXYFqN3ue4\n",
            "5036                                                                               'The way you move is like a full on rainstorm and I'm a house of cards'\n",
            "5060                                                                                           wowo--=== 12000 Nigerian refugees repatriated from Cameroon\n",
            "5174                                                           To All The Meat-Loving Feminists Of The World Riot Grill Has Arrived http://t.co/TiOst8oKvX\n",
            "5198                                 http://t.co/wspuXOrEWb  Cindy Noonan@CindyNoonan-Heartbreak in #Baltimore #Rioting #YAHIstorical #UndergroundRailraod\n",
            "5225            @accionempresa Chinas stock market crash this summer has sparked interest from bargain hunt... http://t.co/s0Eyq1wEHE @gerenciatodos \n",
            "5468                                      Do you feel like you are sinking in low self-image? Take the quiz: http://t.co/JvjALYg2n1 http://t.co/qXMWELJbc0\n",
            "5947                                                In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!\n",
            "5960                                                 Heres how media in Pakistan covered the capture of terrorist Mohammed Naved http://t.co/3MtWh0jJns\n",
            "6006                                                                                        @OriginalFunko @Spencers THUNDER BUDDYS!!!! THUNDER BUDDYS!!!!\n",
            "6141                                                                         Hollywood Movie About Trapped Miners Released in Chile http://t.co/EXQKmlg4NJ\n",
            "6251  @helene_yancey GodsLove &amp; #thankU my sister Helene for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "6660              TWIA board approves 5 percent rate hike: The Texas Windstorm Insurance Association (TWIA) Board of Directors v... http://t.co/esEMjRn5cC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDGiSymJVPBT",
        "colab_type": "text"
      },
      "source": [
        "Having read each tweet individually, I have created a dictionary with the **tweet index** and the **manually assigned label**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeXjxYS1XgLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manual_labels = {\n",
        "    224:0, 471:0, 509:1, 525:0, 1054:1,\n",
        "    1079:0, 1096:0, 1103:0, 1112:1, 1947:0,\n",
        "    1971:0, 2076:0, 2292:0, 2442:0, 2445:0,\n",
        "    2656:0, 2807:1, 2880:0, 3319:0, 3372:1,\n",
        "    3698:0, 3849:0, 3897:0, 4008:0, 4009:0,\n",
        "    4341:0, 4475:0, 4816:0, 5036:0, 5060:0,\n",
        "    5174:0, 5198:1, 5225:0, 5468:0, 5947:0,\n",
        "    5960:0, 6006:0, 6141:0, 6251:0, 6660:0\n",
        "}\n",
        "\n",
        "for k,v in manual_labels.items():\n",
        "  train.loc[k,'target'] = v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwDxM9bVZvho",
        "colab_type": "code",
        "outputId": "7c524ee6-89a6-4afc-99f0-4cabe0cc80d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train[train['target'] == 0.5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsFf7rMiVfRS",
        "colab_type": "text"
      },
      "source": [
        "All split votes have been resolved. Next, I will establish some baseline models upon which I can improve with cleaning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fP3_xWdvGtbF"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N69szSDj3kJ",
        "colab_type": "text"
      },
      "source": [
        "# 3. Baseline Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBS_DHu4DLP4",
        "colab_type": "text"
      },
      "source": [
        "In this section, I establish baseline Logistic Regression, Naive Bayes, and Support Vector Machine (SVM) models. Prior to doing so, I create embedded documents of the tweets using one of the universal sentence encoder created by Google.\n",
        "\n",
        "<br>\n",
        "\n",
        "For each family, I train different algorithms. See below:\n",
        "\n",
        "- **Logistic Regression** - _Basic Logistic Regression_ and _Ridge Classifier_ models are trained.\n",
        "- **Naive Bayes** - _Bernoulli Naive Bayes_ and _Gaussian Bayes_ models are trained.\n",
        "- **SVM** - _Basic Support Vector Classifier_ and _Nu-Support Vector Classifier_ models are trained.\n",
        "\n",
        "<br>\n",
        "\n",
        "Where appropriate, hyper-parameters are optimized and the models are evaluated using 5-fold cross-validation. This gives us good baselines upon which to improve.\n",
        "\n",
        "<br>\n",
        "\n",
        "Finally, I used the three most promissing models to predict the labels for the test set and submitted the results to Kaggle. I also used a stacking ensemble approach to see if results of the three models combined were better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHuPSvJfvc4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install --user tensorflow_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ2GA36FvO3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
        "from sklearn.svm import LinearSVC, SVC, NuSVC\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import tensorflow_text\n",
        "\n",
        "from functools import partial \n",
        "from tqdm import tqdm #for progress bar\n",
        "\n",
        "cv = 5\n",
        "rs = 123\n",
        "np.random.seed(rs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezXVpBTDn-M9",
        "colab_type": "text"
      },
      "source": [
        "## Vectorize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHeSEEVt9ZS_",
        "colab_type": "text"
      },
      "source": [
        "To vectorize the text, I use the multilingual universal sentence encoder from [TensorFlow Hub](https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3), which was published by Google and is designed for text classification tasks such as ours.\n",
        "\n",
        "<br>\n",
        "\n",
        "First, I must load the the encoder directly from the webpage using the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0Ece3ogwGvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTIvaysw8nns",
        "colab_type": "text"
      },
      "source": [
        "With the universal encoder loaded, I loop over each tweet and create a sentence embedding for it. Each of these embeddings is then appended to an array. This is done for both the train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg820Za1_QNj",
        "colab_type": "code",
        "outputId": "56b4c43e-3b94-4025-c2c5-01a3895b348a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train = []\n",
        "for r in tqdm(train.text.values):\n",
        "  emb = use(r)\n",
        "  review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_train.append(review_emb)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = train.target.values\n",
        "\n",
        "X_test = []\n",
        "for r in tqdm(test.text.values):\n",
        "  emb = use(r)\n",
        "  review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_test.append(review_emb)\n",
        "\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:27<00:00, 78.57it/s]\n",
            "100%|| 3263/3263 [00:40<00:00, 80.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NEcnleNA7uO",
        "colab_type": "text"
      },
      "source": [
        "Having created embeddings for the tweets in the two dataframes, I save them to avoid having to repeat this step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW4Shf3Zz7Wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('sentence_embeddings.pkl', 'wb') as f:\n",
        "    pickle.dump([X_train, y_train, X_test], f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBcZhFWfBBjH",
        "colab_type": "text"
      },
      "source": [
        "The code below can be used to reload the previously saved arrays of embedded tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qapPgnoo0E7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('sentence_embeddings.pkl', 'rb') as f:\n",
        "    X_train, y_train, X_test = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MfCjmr2BKRM",
        "colab_type": "text"
      },
      "source": [
        "Here, train and test sets are created in preperation for modelling. Test size is set to 20% of the entire training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMqQzylanV7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, test_arrays, y, test_labels = train_test_split(X_train, y_train, random_state = rs, test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcD3vzzEno8n",
        "colab_type": "text"
      },
      "source": [
        "## Baseline Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq1jK2OjJjTE",
        "colab_type": "text"
      },
      "source": [
        "Here, two logistic regressions are trained and optimized. One is a basic logistic regression and the other is a ridge classifier.\n",
        "\n",
        "The main difference between the two is the loss function. While logisitic regression uses a cross-entropy loss, ridge does not ([source](https://stackoverflow.com/questions/53911663/what-does-sklearn-ridgeclassifier-do/53912015))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQwy8_BN2qTY",
        "colab_type": "text"
      },
      "source": [
        "### Basic Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlaL8qUszCau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_param_selection(X, y, folds=cv, random_state=rs):\n",
        "  param_grid = {\n",
        "      'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "      'C': np.arange(0.1, 1.0, 0.1),\n",
        "      'fit_intercept': [True, False],\n",
        "      'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "      }\n",
        "  random_search = RandomizedSearchCV(LogisticRegression(max_iter=10000, random_state=random_state), param_grid, cv = folds, n_jobs = 8)\n",
        "  random_search.fit(X, y)\n",
        "  random_search.best_params_\n",
        "  return random_search\n",
        "\n",
        "lr_model = lr_param_selection(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqTyUR463LU0",
        "colab_type": "code",
        "outputId": "d42785ae-df43-4f57-d2d8-e8ed52390659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cross_val_score(lr_model, X, y, cv=cv, scoring=\"f1\").mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7567454231456395"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwoHdz3u1Sg7",
        "colab_type": "code",
        "outputId": "b460c757-f91d-4fdb-faaf-94ed4b7d2352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(\"F1-Score: %.2f\" % f1_score(test_labels, lr_model.predict(test_arrays)))\n",
        "print(classification_report(test_labels, lr_model.predict(test_arrays)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score: 0.75\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.88      0.84       808\n",
            "         1.0       0.81      0.70      0.75       561\n",
            "\n",
            "    accuracy                           0.81      1369\n",
            "   macro avg       0.81      0.79      0.79      1369\n",
            "weighted avg       0.81      0.81      0.80      1369\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LptcEunD2t7K",
        "colab_type": "text"
      },
      "source": [
        "### Ridge Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsnZ4is0yfhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rc_param_selection(X, y, folds=cv, random_state=rs):\n",
        "  param_grid = {\n",
        "      'alpha': np.arange(0, 3, 0.1),\n",
        "      'fit_intercept': [True, False],\n",
        "      'normalize': [True, False],\n",
        "      'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
        "      }\n",
        "  random_search = RandomizedSearchCV(RidgeClassifier(max_iter=10000, random_state=random_state), param_grid, cv = folds, n_jobs = 8)\n",
        "  random_search.fit(X, y)\n",
        "  random_search.best_params_\n",
        "  return random_search\n",
        "\n",
        "rc_model = rc_param_selection(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SWC15jp3Dnf",
        "colab_type": "code",
        "outputId": "041ecb1e-0d53-4bbf-d35c-f89f754224a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "cross_val_score(rc_model, X, y, cv=cv, scoring=\"f1\").mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7567670671793278"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IZOUa471sl_",
        "colab_type": "code",
        "outputId": "6684e6a1-2b38-40f9-9220-a775341b2e07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(\"F1-Score: %.2f\" % f1_score(test_labels, rc_model.predict(test_arrays)))\n",
        "print(classification_report(test_labels, rc_model.predict(test_arrays)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score: 0.72\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.90      0.84       808\n",
            "         1.0       0.81      0.65      0.72       561\n",
            "\n",
            "    accuracy                           0.79      1369\n",
            "   macro avg       0.80      0.77      0.78      1369\n",
            "weighted avg       0.80      0.79      0.79      1369\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd_EFhTNodaR",
        "colab_type": "text"
      },
      "source": [
        "## Baseline Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEPhDqEb2ODy",
        "colab_type": "text"
      },
      "source": [
        "### Bernoulli Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPgJ1Ig8ot-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bnb_param_selection(X, y, folds=cv, random_state=rs):\n",
        "  param_grid = {\n",
        "      'alpha': np.arange(0, 3, 0.1)\n",
        "      }\n",
        "  random_search = RandomizedSearchCV(BernoulliNB(), param_grid, cv = folds, n_jobs = 8)\n",
        "  random_search.fit(X, y)\n",
        "  random_search.best_params_\n",
        "  return random_search\n",
        "\n",
        "bnb_model = bnb_param_selection(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQOyo_Un23VI",
        "colab_type": "code",
        "outputId": "77f971dc-9067-47b7-b3b8-e24bd2def367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cross_val_score(bnb_model, X, y, cv=cv, scoring=\"f1\").mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7380695061583131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx0xSeDG155-",
        "colab_type": "code",
        "outputId": "01ca3351-a290-4276-f024-5be66cbc93d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(\"F1-Score: %.2f\" % f1_score(test_labels, bnb_model.predict(test_arrays)))\n",
        "print(classification_report(test_labels, bnb_model.predict(test_arrays)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score: 0.71\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.82      0.80       808\n",
            "         1.0       0.72      0.70      0.71       561\n",
            "\n",
            "    accuracy                           0.77      1369\n",
            "   macro avg       0.76      0.76      0.76      1369\n",
            "weighted avg       0.77      0.77      0.77      1369\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjziBIai2NF3",
        "colab_type": "text"
      },
      "source": [
        "### Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuLV_80Z2Vu2",
        "colab_type": "text"
      },
      "source": [
        "Explanation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NWuAjYXiAk3",
        "colab_type": "code",
        "outputId": "993770ae-ffd1-47c0-c814-53cf5d91794e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gnb = GaussianNB()\n",
        "# gnb.fit(X, y)\n",
        "\n",
        "cross_val_score(gnb, X, y, cv=cv, scoring=\"f1\").mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7477351007039822"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pe9VEePWaM2",
        "colab_type": "code",
        "outputId": "12ee002b-6767-4093-fbaf-e88cc6aa651c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(\"F1-Score: %.2f\" % f1_score(test_labels, gnb.predict(test_arrays)))\n",
        "print(classification_report(test_labels, gnb.predict(test_arrays)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score: 0.71\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.81      0.81       808\n",
            "         1.0       0.72      0.70      0.71       561\n",
            "\n",
            "    accuracy                           0.77      1369\n",
            "   macro avg       0.76      0.76      0.76      1369\n",
            "weighted avg       0.77      0.77      0.77      1369\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1POWfbGvhIzJ",
        "colab_type": "text"
      },
      "source": [
        "## Baseline SVMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqjkWZHF2ej8",
        "colab_type": "text"
      },
      "source": [
        "### Basic Support Vector Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_8iqqWM3X4V",
        "colab_type": "code",
        "outputId": "644c649a-686b-404e-cda4-4740c51a2d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def svc_param_selection(X, y, folds=cv, random_state=rs):\n",
        "    param_grid = {\n",
        "        'C': [1.070, 1.074, 1.075, 1.1, 1.125],\n",
        "        'gamma' : [2.065,2.075, 2.08]}\n",
        "    random_search = RandomizedSearchCV(SVC(kernel='rbf'), param_grid, cv = folds, n_jobs = -1, random_state = random_state)\n",
        "    random_search.fit(X, y)\n",
        "    random_search.best_params_\n",
        "    return random_search\n",
        "\n",
        "svc_model = svc_param_selection(X, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H0sna4N31a6",
        "colab_type": "code",
        "outputId": "5c0706b6-23f0-475f-a9b8-bf5279ec1ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cross_val_score(svc_model, X, y, cv=cv, scoring=\"f1\").mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7652937127625976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Qv_Qw_34In",
        "colab_type": "code",
        "outputId": "a31e211f-3202-4fa7-c53a-dd92e75a00c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(\"F1-Score: %.2f\" % f1_score(test_labels, svc_model.predict(test_arrays)))\n",
        "print(classification_report(test_labels, svc_model.predict(test_arrays)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score: 0.76\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.91      0.86       808\n",
            "         1.0       0.85      0.69      0.76       561\n",
            "\n",
            "    accuracy                           0.82      1369\n",
            "   macro avg       0.83      0.80      0.81      1369\n",
            "weighted avg       0.82      0.82      0.82      1369\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXvRn_3I2iKy",
        "colab_type": "text"
      },
      "source": [
        "### Nu-Support Vector Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6OIdYtQhm_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nsvc_param_selection(X, y, folds=cv, random_state=rs):\n",
        "    param_grid = {\n",
        "        'nu': np.arange(0.1, 1.0, 0.1),\n",
        "        'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],\n",
        "        'degree': range(1, 10),\n",
        "        'gamma': ['scale', 'auto'],\n",
        "        'coef0': np.arange(0, 1, 0.05),\n",
        "        'shrinking': [True, False],\n",
        "        'probability':[True, False],\n",
        "        'decision_function_shape': ['ovo', 'ovr']\n",
        "        }\n",
        "    random_search = RandomizedSearchCV(NuSVC(), param_grid, cv=folds, n_jobs=-1, random_state=random_state)\n",
        "    random_search.fit(X, y)\n",
        "    random_search.best_params_\n",
        "    return random_search\n",
        "\n",
        "nsvc_model = nsvc_param_selection(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIhAL8VE4QD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_val_score(nsvc_model, X, y, cv=cv, scoring='f1').mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPVZB_Ag4U6F",
        "colab_type": "code",
        "outputId": "e62e6060-e83c-4d85-e7c4-75394c213f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(\"F1-Score: %.2f\" % f1_score(test_labels, nsvc_model.predict(test_arrays)))\n",
        "print(classification_report(test_labels, nsvc_model.predict(test_arrays)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score: 0.73\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.90      0.84       808\n",
            "         1.0       0.82      0.66      0.73       561\n",
            "\n",
            "    accuracy                           0.80      1369\n",
            "   macro avg       0.81      0.78      0.79      1369\n",
            "weighted avg       0.80      0.80      0.80      1369\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UugcJFwndvcZ",
        "colab_type": "text"
      },
      "source": [
        "## Save and Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EH4aowpUsV2",
        "colab_type": "text"
      },
      "source": [
        "Here, I save the models and make predictions on the test set using the optimized Logistic Regression, Bernoulli Naive Bayes and Support Vector Classifier. I also stack the three and take the majority vote.\n",
        "\n",
        "<br>\n",
        "\n",
        "For each of the predictions, a loop is used to label tweets with high cosine similarity with '1' or '0' depending on what is most popular among the similar tweets. This is a similar approach to what was used earlier for similar tweets in the training set, except that here, tweets aren't removed. The majority label is simply applied to all the tweets in the group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL6V-uiCdw5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import dump, load"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNilfYZqLd-R",
        "colab_type": "code",
        "outputId": "a3d67372-d02a-46dc-856c-20f147b2806c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dump(lr_model, 'lr_base_model.joblib')\n",
        "dump(rc_model, 'rc_base_model.joblib')\n",
        "dump(bnb_model, 'bnb_base_model.joblib')\n",
        "dump(svc_model, 'svc_base_model.joblib')\n",
        "dump(nsvc_model, 'nsvc_base_model.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nsvc_base_model.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7g6RM7XLIY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_model = load('lr_base_model.joblib')\n",
        "rc_model = load('rc_base_model.joblib')\n",
        "bnb_model = load('bnb_base_model.joblib')\n",
        "svc_model = load('svc_base_model.joblib')\n",
        "nsvc_model = load('nsvc_base_model.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJxwB2Syc6AT",
        "colab_type": "text"
      },
      "source": [
        "### Make Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SivMzvteWPzY",
        "colab_type": "text"
      },
      "source": [
        "Here, four sets of predictions are made, with one being the stacked prediction of the other three."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiXvyACNTYUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_pred = lr_model.predict(X_test)\n",
        "bnb_pred = bnb_model.predict(X_test)\n",
        "svc_pred = svc_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DupcH5KLT10V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission['target'] = lr_pred\n",
        "\n",
        "for k in similar_test.keys():\n",
        "  summation = submission.loc[similar_test[k],:]['target'].sum() + submission.loc[k,:]['target']\n",
        "  count = len(similar[k]) + 1\n",
        "  mean = summation/count\n",
        "  if mean > 0.5:\n",
        "    submission.loc[k,'target'] = 1\n",
        "    submission.loc[similar_test[k],'target'] = 1\n",
        "  else:\n",
        "    submission.loc[k,'target'] = 0\n",
        "    submission.loc[similar_test[k],'target'] = 0\n",
        "\n",
        "submission.to_csv('base_lr_submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oIn9SA0TC14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission['target'] = bnb_pred\n",
        "\n",
        "for k in similar_test.keys():\n",
        "  summation = submission.loc[similar_test[k],:]['target'].sum() + submission.loc[k,:]['target']\n",
        "  count = len(similar[k]) + 1\n",
        "  mean = summation/count\n",
        "  if mean > 0.5:\n",
        "    submission.loc[k,'target'] = 1\n",
        "    submission.loc[similar_test[k],'target'] = 1\n",
        "  else:\n",
        "    submission.loc[k,'target'] = 0\n",
        "    submission.loc[similar_test[k],'target'] = 0\n",
        "\n",
        "submission.to_csv('base_bnb_submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PzD8wCpTjg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission['target'] = svc_pred\n",
        "\n",
        "for k in similar_test.keys():\n",
        "  summation = submission.loc[similar_test[k],:]['target'].sum() + submission.loc[k,:]['target']\n",
        "  count = len(similar[k]) + 1\n",
        "  mean = summation/count\n",
        "  if mean > 0.5:\n",
        "    submission.loc[k,'target'] = 1\n",
        "    submission.loc[similar_test[k],'target'] = 1\n",
        "  else:\n",
        "    submission.loc[k,'target'] = 0\n",
        "    submission.loc[similar_test[k],'target'] = 0\n",
        "\n",
        "submission.to_csv('base_svc_submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PysJM6qqWWbT",
        "colab_type": "text"
      },
      "source": [
        "### Initial Kaggle Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_0NLLzPWcv7",
        "colab_type": "text"
      },
      "source": [
        "Of the predictions made, only the stacked prediction was submitted to Kaggle. The prediction was established using the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3eVT4DMTk9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stack_pred = []\n",
        "\n",
        "for i in range(len(lr_pred)):\n",
        "  if (lr_pred[i] + bnb_pred[i] + svc_pred[i]) >= 2:\n",
        "    stack_pred.append(1)\n",
        "  else:\n",
        "    stack_pred.append(0)\n",
        "    \n",
        "\n",
        "submission['target'] = stack_pred\n",
        "\n",
        "for k in similar_test.keys():\n",
        "  summation = submission.loc[similar_test[k],:]['target'].sum() + submission.loc[k,:]['target']\n",
        "  count = len(similar[k]) + 1\n",
        "  mean = summation/count\n",
        "  if mean > 0.5:\n",
        "    submission.loc[k,'target'] = 1\n",
        "    submission.loc[similar_test[k],'target'] = 1\n",
        "  else:\n",
        "    submission.loc[k,'target'] = 0\n",
        "    submission.loc[similar_test[k],'target'] = 0\n",
        "\n",
        "submission.to_csv('base_stacked_submission.csv', index = False)\n",
        "# F1_score: 0.81799"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIaoGEEEWv1X",
        "colab_type": "text"
      },
      "source": [
        "**KAGLE SCORE:** 81.799\n",
        "\n",
        "This initial prediction yielded a relatively good score, despite no cleaning having been done to the text. I try to improve upon this score below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB-lghhVrCXO",
        "colab_type": "text"
      },
      "source": [
        "# 4. Further Cleaning and Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5Gc1vT1NnzG",
        "colab_type": "text"
      },
      "source": [
        "In this section, I clean the text in the training set in an attempt to improve model performance. The two models selected for further fine-tuning are:\n",
        "\n",
        "1. Basic Logistic Regression\n",
        "2. Basic Support Vector Classifier\n",
        "\n",
        "\n",
        "At every step of text cleaning, a model is trained and evaluated to determine if the cleaning step improved, hindered or had no effect on performance. This approach slows down training, but is likely to lead to more robust results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFfbaeNjvit7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install colorama\n",
        "# !pip install pyspellchecker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_2sEs-Y72b_",
        "colab_type": "code",
        "outputId": "d2541a7f-d83f-4498-e7d5-ef00b3d78cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "from spellchecker import SpellChecker\n",
        "import unicodedata\n",
        "from colorama import Fore, Style\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "tfidf = TfidfVectorizer(min_df=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uq-XYMSMqWfh"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSt4PbxQiEdR",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtnpQzfnMxB5",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs2uk9t5OeE3",
        "colab_type": "text"
      },
      "source": [
        "Here, I define some objects that will be used throughout this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-z9CWN0MwVo",
        "colab_type": "code",
        "outputId": "6e33a6db-69cc-49ec-c2f1-40e4b0231196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "reference = 'processed_text_lr'\n",
        "train['processed_text_lr'] = train['text'].copy()\n",
        "clf = lr_model\n",
        "# base = cross_val_score(clf, X, y, cv=cv, scoring=\"f1\").mean()\n",
        "baseline = base.copy()\n",
        "cv = 5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4s7R5ubUJe2",
        "colab_type": "text"
      },
      "source": [
        "#### Helper Dictionaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iE4g3Q8Olrc",
        "colab_type": "text"
      },
      "source": [
        "Here, two dictionaries are defined, which will be used later in the cleaning process. One is for the expansion of contraction, which was retrieved from [here](https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/bonus%20content/nlp%20proven%20approach/contractions.py). The other is for the expansion of abbreviations, which was pulled from [here](https://www.kaggle.com/nmaguette/up-to-date-list-of-slangs-for-text-preprocessing/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-pYvZYJUH3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/bonus%20content/nlp%20proven%20approach/contractions.py\n",
        "\n",
        "CONTRACTION_MAP = {\n",
        "    \"ain't\": \"is not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"can't've\": \"cannot have\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"couldn't've\": \"could not have\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hadn't've\": \"had not have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'd've\": \"he would have\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he'll've\": \"he he will have\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"I'd\": \"I would\",\n",
        "    \"I'd've\": \"I would have\",\n",
        "    \"I'll\": \"I will\",\n",
        "    \"I'll've\": \"I will have\",\n",
        "    \"I'm\": \"I am\",\n",
        "    \"I've\": \"I have\",\n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\",\n",
        "    \"i'll\": \"i will\",\n",
        "    \"i'll've\": \"i will have\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so as\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuEUVGLEUMnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/nmaguette/up-to-date-list-of-slangs-for-text-preprocessing/\n",
        "\n",
        "abbreviations = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"2k10\": \"2010\",\n",
        "    \"2k11\": \"2011\",\n",
        "    \"2k12\": \"2012\",\n",
        "    \"2k13\": \"2013\",\n",
        "    \"2k14\": \"2014\",\n",
        "    \"2k15\": \"2015\",\n",
        "    \"2k16\": \"2016\",\n",
        "    \"2k17\": \"2017\",\n",
        "    \"2k18\": \"2018\",\n",
        "    \"2k19\": \"2019\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\", \n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "    \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\", \n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmaoo\" : \"laugh my ass off\",\n",
        "    \"lmaaoo\" : \"laugh my ass off\",\n",
        "    \"lmaao\" : \"laugh my ass off\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lool\" : \"laughing out loud\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\n",
        "    \"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\",\n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retweet\", \n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retweet\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "    \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\", \n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlSsSUxpeMxW",
        "colab_type": "text"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxIrMGp-PS2Y",
        "colab_type": "text"
      },
      "source": [
        "Below are a number of useful user-defined functions that will aid throughout the cleaning process. Though they will be described in more detail when used, one in particular are worth highlighting here:\n",
        "\n",
        "- **try_step()** - this function takes a function as its input, as well as other optional arguments, and applies the function to the corpus, saving the results in a temporary column. It then trains and evaluates a model on the new column to determine if the function improved performance. If it did, then the changes are applied to the `processed_text` column and the baseline score is updated. This function allows for the evaluation of different cleaning approaches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC3qqeFTjWex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def try_step(function, vectorizer = 'universal', model = clf, base = baseline, reference = reference, target = 'temp', scoring = 'f1', folds = cv, coerce = False, random_state = rs, **kwargs):\n",
        "  \"\"\"\n",
        "  This function takes a function as its input, as well as other optional arguments.\n",
        "  It applies the function to the text and computes the resultant change in the target metric (F1-Score by default).\n",
        "  \"\"\"\n",
        "  global baseline\n",
        "\n",
        "  train[target] = train[reference].apply(lambda x: function(x, **kwargs))\n",
        "\n",
        "  if vectorizer == 'basic':\n",
        "    X_train, X_test, y, y_test = train_test_split(train[target], train['target'], random_state = random_state)\n",
        "    X = tfidf.fit_transform(X_train)\n",
        "    score = cross_val_score(model, X, y, cv = folds, scoring = scoring).mean()\n",
        "    \n",
        "  if vectorizer == 'universal':\n",
        "    X_temp = []\n",
        "    \n",
        "    for r in tqdm(train[reference].values):\n",
        "      emb = use(r)\n",
        "      review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "      X_temp.append(review_emb)\n",
        "\n",
        "    X_temp = np.array(X_temp)\n",
        "    y_train = train['target'].values\n",
        "    X, test_arrays, y, test_labels = train_test_split(X_temp, y_train, random_state = random_state, test_size = 0.3)\n",
        "\n",
        "  score = cross_val_score(model, X, y, cv = folds, scoring = scoring).mean()\n",
        "  \n",
        "  print(\"Result: \\t\\t %.4f\" % (score))\n",
        "  print(\"Previous baseline: \\t %.4f\" % (baseline))\n",
        "  \n",
        "  if score > baseline:\n",
        "    print(Fore.GREEN + \"Improvement of: \\t %.4f\" % (np.round(score, 4) - np.round(baseline, 4)))\n",
        "    baseline = score\n",
        "    print(Fore.BLACK + \"\\nNew baseline: \\t\\t %.4f\" % (baseline))\n",
        "    train[reference] = train[target]\n",
        "  \n",
        "  elif score == baseline:\n",
        "    print(Fore.BLACK + \"\\nThis step does not change the baseline.\")\n",
        "    train[reference] = train[target]\n",
        "\n",
        "  else:\n",
        "    print(Fore.RED + \"Reduction of: \\t\\t%.4f\" % (score - baseline))\n",
        "    print(Fore.BLACK + \"\\nPrevious baseline remains the best.\")\n",
        "  \n",
        "  if coerce:\n",
        "    train[reference] = train[target]\n",
        "    baseline = score\n",
        "    print('\\nChange coerced')\n",
        "  \n",
        "  del train[target]\n",
        "\n",
        "\n",
        "\n",
        "def get_words(reference):\n",
        "  all_words = []\n",
        "\n",
        "  for tweet in reference:\n",
        "    table = str.maketrans('','',string.punctuation)\n",
        "    text = tweet.translate(table)\n",
        "    for word in text.split():\n",
        "      if word.lower() not in all_words:\n",
        "        all_words.append(word.lower())\n",
        "\n",
        "  return all_words\n",
        "\n",
        "\n",
        "def replace_expression(text, expression, replace_with):\n",
        "  text = re.sub(expression, replace_with, text)\n",
        "  return text\n",
        "\n",
        "\n",
        "def standardize_text(text):\n",
        "  text = text.replace(r\"http\\S+\", \"\")\n",
        "  text = text.replace(r\"http\", \"\")\n",
        "  text = text.replace(r\"@\\S+\", \"\")\n",
        "  text = text.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
        "  text = text.replace(r\"@\", \"at \")\n",
        "  text = text.replace(r\"#\", \"hashtag \")\n",
        "  text = text.lower()\n",
        "  return text\n",
        "\n",
        "\n",
        "def spacing(text):\n",
        "  text = text.replace(r'\\t', ' ')\n",
        "  text = text.replace(r'\\n', ' ')\n",
        "  text = text.replace(r\"\\s+\", \" \")\n",
        "  return text\n",
        "\n",
        "\n",
        "def strip_html_tags(text):\n",
        "  soup = BeautifulSoup(text, \"html.parser\")\n",
        "  stripped_text = soup.get_text()\n",
        "  return stripped_text\n",
        "\n",
        "\n",
        "def remove_punct(text, punctuation):\n",
        "  table=str.maketrans('','', punctuation)\n",
        "  return text.translate(table)\n",
        "\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "  return text\n",
        "\n",
        "\n",
        "def stemming(text):\n",
        "  stemmer = SnowballStemmer(\"english\")\n",
        "  text = [stemmer.stem(word) for word in text.split()]\n",
        "  return \" \".join(text)\n",
        "\n",
        "\n",
        "mycompile = lambda pat:  re.compile(pat, re.UNICODE)\n",
        "\n",
        "NormalEyes = r'[:]'\n",
        "Wink = r'[;]'\n",
        "\n",
        "NoseArea = r'(o|O|-)'\n",
        "\n",
        "HappyMouths = r'[D\\)\\]]'\n",
        "SadMouths = r'[\\(\\[]'\n",
        "Tongue = r'[pP]'\n",
        "OtherMouths = r'[doO/\\\\]'\n",
        "\n",
        "happy_regex =  mycompile( '(\\^_\\^|' + NormalEyes + NoseArea + HappyMouths + ')')\n",
        "sad_regex = mycompile(NormalEyes + NoseArea + SadMouths)\n",
        "wink_regex = mycompile(Wink + NoseArea + HappyMouths)\n",
        "tongue_regex = mycompile(NormalEyes + NoseArea + Tongue)\n",
        "other_regex = mycompile( '('+NormalEyes+'|'+Wink+')'  + NoseArea + OtherMouths )\n",
        "\n",
        "Emoticon = (\n",
        "    \"(\"+NormalEyes+\"|\"+Wink+\")\" +\n",
        "    NoseArea + \n",
        "    \"(\"+Tongue+\"|\"+OtherMouths+\"|\"+SadMouths+\"|\"+HappyMouths+\")\"\n",
        ")\n",
        "\n",
        "emoticon_regex = mycompile(Emoticon)\n",
        "\n",
        "def happy_repl(match):\n",
        "  return '_HAPPY_'+match.group(1).upper()\n",
        "\n",
        "def sad_repl(match):\n",
        "  return '_SAD_'+match.group(1).upper()\n",
        "\n",
        "def wink_repl(match):\n",
        "  return '_WINK_'+match.group(1).upper()\n",
        "\n",
        "def emoticons(text):\n",
        "  text = re.sub( happy_regex, happy_repl, text )\n",
        "  text = re.sub( sad_regex, sad_repl, text )\n",
        "  text = re.sub( wink_regex, wink_repl, text )\n",
        "  return text\n",
        "\n",
        "\n",
        "spell = SpellChecker()\n",
        "def correct_spellings(text):\n",
        "  corrected_text = []\n",
        "  misspelled_words = spell.unknown(text.split())\n",
        "  for word in text.split():\n",
        "      if word in misspelled_words:\n",
        "          corrected_text.append(spell.correction(word))\n",
        "          print(word, ' '*(20-len(word)), \"===>\\t\", spell.correction(word))\n",
        "      else:\n",
        "          corrected_text.append(word)\n",
        "  return \" \".join(corrected_text)\n",
        "\n",
        "\n",
        "def remove_stopwords(text, words):\n",
        "  tokens = [x for x in word_tokenize(text) if x.lower() not in words]\n",
        "  return \" \".join(tokens)\n",
        "\n",
        "\n",
        "def stopwords_to_remove(words, baseline, reference, vectorizer = 'basic', cv = cv, clf = clf, scoring = 'f1', random_state = rs):\n",
        "  stop = []\n",
        "  i = 1\n",
        "\n",
        "  for word in words:\n",
        "    stop.append(word)\n",
        "    train['temp'] = reference.apply(remove_stopwords, words = stop)\n",
        "\n",
        "    if vectorizer == 'universal':\n",
        "      X_temp = []\n",
        "    \n",
        "      for r in tqdm(train['temp'].values):\n",
        "        emb = use(r)\n",
        "        review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "        X_temp.append(review_emb)\n",
        "\n",
        "      X_temp = np.array(X_temp)\n",
        "      y_train = train['target'].values\n",
        "      X, test_arrays, y, test_labels = train_test_split(X_temp, y_train, random_state = random_state, test_size = 0.3)\n",
        "      score = cross_val_score(clf, X, y, cv = cv, scoring = scoring).mean()\n",
        "\n",
        "    if vectorizer == 'basic':\n",
        "      X, X_t, y, y_t = train_test_split(train['temp'], train['target'], random_state = random_state)\n",
        "      X = tfidf.fit_transform(X)\n",
        "      score = cross_val_score(clf, X, y, cv = cv, scoring = scoring).mean()\n",
        "    \n",
        "    \n",
        "    print(\"{}%\\t\".format(np.round((i/len(all_stopwords)*100), 2)), np.round(score, 4),'    \\t', stop)\n",
        "    i += 1\n",
        "\n",
        "    if score > baseline:\n",
        "      baseline = score\n",
        "      reference = reference.apply(remove_stopwords, words = stop)\n",
        "      \n",
        "    else:\n",
        "      stop.remove(word)\n",
        "  \n",
        "  print('\\nSelected stopwords to remove:\\n', stop)\n",
        "  return stop\n",
        "\n",
        "\n",
        "def convert_abbrev(word, words):\n",
        "  return words[word.lower()] if word.lower() in words.keys() else word\n",
        "\n",
        "\n",
        "def convert_abbrev_in_text(text, words):\n",
        "  tokens = word_tokenize(text)\n",
        "  tokens = [convert_abbrev(word, words) for word in tokens]\n",
        "  return ' '.join(tokens)\n",
        "\n",
        "\n",
        "def abbreviations_to_replace(words, baseline, reference, vectorizer = 'basic', cv = cv, clf = clf, scoring = 'f1', random_state = rs):\n",
        "  abbr = {}\n",
        "  i = 1\n",
        "\n",
        "  for k, v in words.items():\n",
        "    abbr[k] = v\n",
        "    train['temp'] = reference.apply(lambda x: convert_abbrev_in_text(x, words = abbr))\n",
        "    \n",
        "    if vectorizer == 'universal':\n",
        "      X_temp = []\n",
        "      \n",
        "      for r in tqdm(train['temp'].values):\n",
        "        emb = use(r)\n",
        "        review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "        X_temp.append(review_emb)\n",
        "\n",
        "      X_temp = np.array(X_temp)\n",
        "      y_train = train['target'].values\n",
        "      X, test_arrays, y, test_labels = train_test_split(X_temp, y_train, random_state = random_state, test_size = 0.3)\n",
        "      score = cross_val_score(clf, X, y, cv = cv, scoring = scoring).mean()\n",
        "\n",
        "    if vectorizer == 'basic':\n",
        "      X_train, X_test, y, y_test = train_test_split(train['temp'], train['target'], random_state = rs)\n",
        "      X = tfidf.fit_transform(X_train)\n",
        "      score = cross_val_score(clf, X, y, cv=cv, scoring=scoring).mean()\n",
        "\n",
        "    print(\"{}%\\t\".format(np.round((i/len(words)*100), 2)), np.round(score, 4),'  \\t', abbr)\n",
        "    i += 1\n",
        "    \n",
        "    if score > baseline:\n",
        "      baseline = score\n",
        "      reference = reference.apply(lambda x: convert_abbrev_in_text(x, words = abbr))\n",
        "\n",
        "    else:\n",
        "      del abbr[k]\n",
        "\n",
        "  return abbr\n",
        "  print('\\nSelected abbreviations to replace:\\n', abbr)\n",
        "\n",
        "\n",
        "def expand_contractions(text, contraction_mapping):\n",
        "    \n",
        "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
        "                                      flags=re.IGNORECASE|re.DOTALL)\n",
        "    def expand_match(contraction):\n",
        "        match = contraction.group(0)\n",
        "        first_char = match[0]\n",
        "        expanded_contraction = contraction_mapping.get(match)\\\n",
        "                                if contraction_mapping.get(match)\\\n",
        "                                else contraction_mapping.get(match.lower())                       \n",
        "        expanded_contraction = first_char+expanded_contraction[1:]\n",
        "        return expanded_contraction\n",
        "        \n",
        "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
        "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "    return expanded_text\n",
        "\n",
        "\n",
        "def contractions_to_expand(words, baseline, reference, vectorizer = 'basic', cv = cv, clf = clf, scoring = 'f1', random_state = rs):\n",
        "  contractions = {}\n",
        "  i = 1\n",
        "\n",
        "  for k, v in words.items():\n",
        "    contractions[k] = v\n",
        "    train['temp'] = reference.apply(lambda x: expand_contractions(x, contraction_mapping = contractions))\n",
        "    \n",
        "    if vectorizer == 'universal':\n",
        "      X_temp = []\n",
        "      \n",
        "      for r in tqdm(train['temp'].values):\n",
        "        emb = use(r)\n",
        "        review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "        X_temp.append(review_emb)\n",
        "\n",
        "      X_temp = np.array(X_temp)\n",
        "      y_train = train['target'].values\n",
        "      X, test_arrays, y, test_labels = train_test_split(X_temp, y_train, random_state = random_state, test_size = 0.3)\n",
        "      score = cross_val_score(clf, X, y, cv = cv, scoring = scoring).mean()\n",
        "\n",
        "    if vectorizer == 'basic':\n",
        "      X_train, X_test, y, y_test = train_test_split(train['temp'], train['target'], random_state = random_state)\n",
        "      X = tfidf.fit_transform(X_train)\n",
        "      score = cross_val_score(clf, X, y, cv = cv, scoring = scoring).mean()\n",
        "    \n",
        "    print(\"{}%\\t\".format(np.round((i/len(words)*100), 2)), np.round(score, 4),'  \\t', contractions)\n",
        "    i += 1\n",
        "    \n",
        "    if score > baseline:\n",
        "      baseline = score\n",
        "      reference = reference.apply(lambda x: expand_contractions(x, contraction_mapping = contractions))\n",
        "  \n",
        "    else:\n",
        "      del contractions[k]\n",
        "    \n",
        "    return contractions\n",
        "    print('\\nContractions to expand:\\n', contractions)\n",
        "\n",
        "\n",
        "def remove_punct(text, punctuation):\n",
        "    table=str.maketrans('','', punctuation)\n",
        "    return text.translate(table)\n",
        "\n",
        "\n",
        "def punct_to_remove(baseline, reference, vectorizer = 'basic', cv = cv, clf = clf, scoring = 'f1', random_state = rs):\n",
        "  punc = ''\n",
        "  i = 1\n",
        "  \n",
        "  for p in string.punctuation:\n",
        "    punc = punc+p\n",
        "    train['temp'] = reference.apply(remove_punct, punctuation = punc)\n",
        "\n",
        "    if vectorizer == 'universal':\n",
        "      X_temp = []\n",
        "      \n",
        "      for r in tqdm(train['temp'].values):\n",
        "        emb = use(r)\n",
        "        review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "        X_temp.append(review_emb)\n",
        "\n",
        "      X_temp = np.array(X_temp)\n",
        "      y_train = train['target'].values\n",
        "      X, test_arrays, y, test_labels = train_test_split(X_temp, y_train, random_state = random_state, test_size = 0.3)\n",
        "      score = cross_val_score(clf, X, y, cv = cv, scoring = scoring).mean()\n",
        "\n",
        "    if vectorizer == 'basic':\n",
        "      X_train, X_test, y, y_test = train_test_split(train['temp'], train['target'], random_state = random_state)\n",
        "      X = tfidf.fit_transform(X_train)\n",
        "      score = cross_val_score(clf, X, y, cv=cv, scoring=scoring).mean()\n",
        "\n",
        "    print(\"{}%\\t\".format(np.round((i/len(string.punctuation)*100), 2)), np.round(score, 4),'  \\t', punc)\n",
        "    i += 1\n",
        "  \n",
        "    if score > baseline:\n",
        "      baseline = score\n",
        "      \n",
        "    else:\n",
        "      punc = punc[:-1]\n",
        "\n",
        "  return punc\n",
        "  print('\\nSelected punctuation to remove:\\n', punc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_6RusD-wk6F",
        "colab_type": "text"
      },
      "source": [
        "#### Regular Expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-GpruYjQgEA",
        "colab_type": "text"
      },
      "source": [
        "Here, a few regular expressions are defined to be used as arguments for the `replace_expression` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--mg4uXWwm6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hashtags = {'expression' : r'#(\\w+)', 'replacement' : '_HASH_'}\n",
        "lengthening = {'expression': r\"(.)\\1{2,}\", 'replacement': r\"\\1\\1\"}\n",
        "special_characters = {'expression': r\"[^a-zA-Z\\'\\.\\,\\d\\s]\", 'replacement': \" \"}\n",
        "\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "                      u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                      u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                      u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                      u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                      u\"\\U00002702-\\U000027B0\"\n",
        "                      u\"\\U000024C2-\\U0001F251\"\n",
        "                      \"]+\", flags=re.UNICODE)\n",
        "\n",
        "emojis = {'expression': emoji_pattern, 'replacement': ' '}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ6ImBo4QV-V",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyGIgYvaXw2r",
        "colab_type": "text"
      },
      "source": [
        "To start, I will list all the words in the training set to see what issues we can try to resolve. Note: the output produced by **get_words** is very crude, with punctuation removed and letters converted to lower-case. It is meant primarily for subsetting dictionaries used during cleaning. However, it gives us a useful high-level overview."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "24eecfae-d8db-43f2-d477-2b5555f18cb3",
        "id": "0A8zFKpu5uxy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "all_words = get_words(train[reference])\n",
        "all_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['our',\n",
              " 'deeds',\n",
              " 'are',\n",
              " 'the',\n",
              " 'reason',\n",
              " 'of',\n",
              " 'this',\n",
              " 'earthquake',\n",
              " 'may',\n",
              " 'allah',\n",
              " 'forgive',\n",
              " 'us',\n",
              " 'all',\n",
              " 'forest',\n",
              " 'fire',\n",
              " 'near',\n",
              " 'la',\n",
              " 'ronge',\n",
              " 'sask',\n",
              " 'canada',\n",
              " 'residents',\n",
              " 'asked',\n",
              " 'to',\n",
              " 'shelter',\n",
              " 'in',\n",
              " 'place',\n",
              " 'being',\n",
              " 'notified',\n",
              " 'by',\n",
              " 'officers',\n",
              " 'no',\n",
              " 'other',\n",
              " 'evacuation',\n",
              " 'or',\n",
              " 'orders',\n",
              " 'expected',\n",
              " '13000',\n",
              " 'people',\n",
              " 'receive',\n",
              " 'wildfires',\n",
              " 'california',\n",
              " 'just',\n",
              " 'got',\n",
              " 'sent',\n",
              " 'photo',\n",
              " 'from',\n",
              " 'ruby',\n",
              " 'alaska',\n",
              " 'as',\n",
              " 'smoke',\n",
              " 'pours',\n",
              " 'into',\n",
              " 'a',\n",
              " 'school',\n",
              " 'rockyfire',\n",
              " 'update',\n",
              " 'hwy',\n",
              " '20',\n",
              " 'closed',\n",
              " 'both',\n",
              " 'directions',\n",
              " 'due',\n",
              " 'lake',\n",
              " 'county',\n",
              " 'cafire',\n",
              " 'flood',\n",
              " 'disaster',\n",
              " 'heavy',\n",
              " 'rain',\n",
              " 'causes',\n",
              " 'flash',\n",
              " 'flooding',\n",
              " 'streets',\n",
              " 'manitou',\n",
              " 'colorado',\n",
              " 'springs',\n",
              " 'areas',\n",
              " 'im',\n",
              " 'on',\n",
              " 'top',\n",
              " 'hill',\n",
              " 'and',\n",
              " 'i',\n",
              " 'can',\n",
              " 'see',\n",
              " 'woods',\n",
              " 'theres',\n",
              " 'an',\n",
              " 'emergency',\n",
              " 'happening',\n",
              " 'now',\n",
              " 'building',\n",
              " 'across',\n",
              " 'street',\n",
              " 'afraid',\n",
              " 'that',\n",
              " 'tornado',\n",
              " 'is',\n",
              " 'coming',\n",
              " 'area',\n",
              " 'three',\n",
              " 'died',\n",
              " 'heat',\n",
              " 'wave',\n",
              " 'so',\n",
              " 'far',\n",
              " 'haha',\n",
              " 'south',\n",
              " 'tampa',\n",
              " 'getting',\n",
              " 'flooded',\n",
              " 'hah',\n",
              " 'wait',\n",
              " 'second',\n",
              " 'live',\n",
              " 'what',\n",
              " 'am',\n",
              " 'gonna',\n",
              " 'do',\n",
              " 'fvck',\n",
              " 'raining',\n",
              " 'florida',\n",
              " 'tampabay',\n",
              " '18',\n",
              " '19',\n",
              " 'days',\n",
              " 'ive',\n",
              " 'lost',\n",
              " 'count',\n",
              " 'bago',\n",
              " 'myanmar',\n",
              " 'we',\n",
              " 'arrived',\n",
              " 'damage',\n",
              " 'bus',\n",
              " '80',\n",
              " 'multi',\n",
              " 'car',\n",
              " 'crash',\n",
              " 'breaking',\n",
              " 'whats',\n",
              " 'up',\n",
              " 'man',\n",
              " 'love',\n",
              " 'fruits',\n",
              " 'summer',\n",
              " 'lovely',\n",
              " 'my',\n",
              " 'fast',\n",
              " 'goooooooaaaaaal',\n",
              " 'ridiculous',\n",
              " 'london',\n",
              " 'cool',\n",
              " 'skiing',\n",
              " 'wonderful',\n",
              " 'day',\n",
              " 'looooool',\n",
              " 'wayi',\n",
              " 'cant',\n",
              " 'eat',\n",
              " 'shit',\n",
              " 'was',\n",
              " 'nyc',\n",
              " 'last',\n",
              " 'week',\n",
              " 'girlfriend',\n",
              " 'cooool',\n",
              " 'you',\n",
              " 'like',\n",
              " 'pasta',\n",
              " 'end',\n",
              " 'bbcmtd',\n",
              " 'wholesale',\n",
              " 'markets',\n",
              " 'ablaze',\n",
              " 'httptcolhyxeohy6c',\n",
              " 'always',\n",
              " 'try',\n",
              " 'bring',\n",
              " 'metal',\n",
              " 'rt',\n",
              " 'httptcoyao1e0xngw',\n",
              " 'africanbaze',\n",
              " 'newsnigeria',\n",
              " 'flag',\n",
              " 'set',\n",
              " 'aba',\n",
              " 'httptco2nndbgwyei',\n",
              " 'crying',\n",
              " 'out',\n",
              " 'for',\n",
              " 'more',\n",
              " 'me',\n",
              " 'plus',\n",
              " 'side',\n",
              " 'look',\n",
              " 'at',\n",
              " 'sky',\n",
              " 'night',\n",
              " 'it',\n",
              " 'httptcoqqsmshaj3n',\n",
              " 'phdsquares',\n",
              " 'mufc',\n",
              " 'theyve',\n",
              " 'built',\n",
              " 'much',\n",
              " 'hype',\n",
              " 'around',\n",
              " 'new',\n",
              " 'acquisitions',\n",
              " 'but',\n",
              " 'doubt',\n",
              " 'they',\n",
              " 'will',\n",
              " 'epl',\n",
              " 'season',\n",
              " 'inec',\n",
              " 'office',\n",
              " 'abia',\n",
              " 'httptco3imaomknna',\n",
              " 'barbados',\n",
              " 'bridgetown',\n",
              " 'jamaica',\n",
              " '\\x89',\n",
              " 'two',\n",
              " 'cars',\n",
              " 'santa',\n",
              " 'cruz',\n",
              " '\\x89',\n",
              " 'head',\n",
              " 'st',\n",
              " 'elizabeth',\n",
              " 'police',\n",
              " 'superintende',\n",
              " 'httptcowdueaj8q4j',\n",
              " 'lord',\n",
              " 'd',\n",
              " 'check',\n",
              " 'these',\n",
              " 'httptcoroi2nsmejj',\n",
              " 'httptco3tj8zjin21',\n",
              " 'httptcoyduixefipe',\n",
              " 'httptcolxtjc87kls',\n",
              " 'nsfw',\n",
              " 'outside',\n",
              " 'youre',\n",
              " 'alive',\n",
              " 'dead',\n",
              " 'inside',\n",
              " 'had',\n",
              " 'awesome',\n",
              " 'time',\n",
              " 'visiting',\n",
              " 'cfc',\n",
              " 'ancop',\n",
              " 'site',\n",
              " 'thanks',\n",
              " 'tita',\n",
              " 'vida',\n",
              " 'taking',\n",
              " 'care',\n",
              " 'soooo',\n",
              " 'pumped',\n",
              " 'southridgelife',\n",
              " 'wanted',\n",
              " 'chicago',\n",
              " 'with',\n",
              " 'preaching',\n",
              " 'not',\n",
              " 'hotel',\n",
              " 'httptcoo9qknbfofx',\n",
              " 'gained',\n",
              " '3',\n",
              " 'followers',\n",
              " 'know',\n",
              " 'your',\n",
              " 'stats',\n",
              " 'grow',\n",
              " 'httptcotiyulif5c6',\n",
              " 'how',\n",
              " 'west',\n",
              " 'burned',\n",
              " 'thousands',\n",
              " 'alone',\n",
              " 'httptcovl5tbr3wbr',\n",
              " 'perfect',\n",
              " 'tracklist',\n",
              " 'life',\n",
              " 'leave',\n",
              " 'first',\n",
              " 'retainers',\n",
              " 'its',\n",
              " 'quite',\n",
              " 'weird',\n",
              " 'better',\n",
              " 'get',\n",
              " 'used',\n",
              " 'have',\n",
              " 'wear',\n",
              " 'them',\n",
              " 'every',\n",
              " 'single',\n",
              " 'next',\n",
              " 'year',\n",
              " 'least',\n",
              " 'deputies',\n",
              " 'shot',\n",
              " 'before',\n",
              " 'brighton',\n",
              " 'home',\n",
              " 'httptcogwnrhmso8k',\n",
              " 'wife',\n",
              " 'six',\n",
              " 'years',\n",
              " 'jail',\n",
              " 'setting',\n",
              " 'niece',\n",
              " 'httptcoev1ahoucza',\n",
              " 'superintendent',\n",
              " 'lanford',\n",
              " 'salmon',\n",
              " 'has',\n",
              " 'r',\n",
              " 'httptcovplr5hka2u',\n",
              " 'httptcosxhw2tnnlf',\n",
              " 'arsonist',\n",
              " 'deliberately',\n",
              " 'black',\n",
              " 'church',\n",
              " 'north',\n",
              " 'carolinaablaze',\n",
              " 'httptcopcxarbh9an',\n",
              " 'noches',\n",
              " 'elbestia',\n",
              " 'alexissanchez',\n",
              " 'happy',\n",
              " 'teammates',\n",
              " 'training',\n",
              " 'hard',\n",
              " 'goodnight',\n",
              " 'gunners',\n",
              " 'httptcouc4j4jhvgr',\n",
              " 'kurds',\n",
              " 'trampling',\n",
              " 'turkmen',\n",
              " 'later',\n",
              " 'while',\n",
              " 'others',\n",
              " 'vandalized',\n",
              " 'offices',\n",
              " 'front',\n",
              " 'diyala',\n",
              " 'httptco4izfdyc3cg',\n",
              " 'truck',\n",
              " 'r21',\n",
              " 'voortrekker',\n",
              " 'ave',\n",
              " 'tambo',\n",
              " 'intl',\n",
              " 'cargo',\n",
              " 'section',\n",
              " 'httptco8kscqkfkkf',\n",
              " 'hearts',\n",
              " 'city',\n",
              " 'gift',\n",
              " 'skyline',\n",
              " 'kiss',\n",
              " 'upon',\n",
              " 'lips',\n",
              " '\\x89',\n",
              " 'httpstcocyompz1a0z',\n",
              " 'tonight',\n",
              " 'los',\n",
              " 'angeles',\n",
              " 'expecting',\n",
              " 'ig',\n",
              " 'fb',\n",
              " 'be',\n",
              " 'filled',\n",
              " 'sunset',\n",
              " 'shots',\n",
              " 'if',\n",
              " 'peeps',\n",
              " 'httptcoicsjgz9te1',\n",
              " 'climate',\n",
              " 'energy',\n",
              " 'httptco9fxmn0l0bd',\n",
              " 'revel',\n",
              " 'yours',\n",
              " 'wmv',\n",
              " 'videos',\n",
              " 'means',\n",
              " 'mac',\n",
              " 'farewell',\n",
              " 'en',\n",
              " 'route',\n",
              " 'dvd',\n",
              " 'gtxrwm',\n",
              " 'progressive',\n",
              " 'greetings',\n",
              " 'about',\n",
              " 'month',\n",
              " 'students',\n",
              " 'would',\n",
              " 'their',\n",
              " 'pens',\n",
              " 'torch',\n",
              " 'publications',\n",
              " 'httptco9fxpixqujt',\n",
              " 'rene',\n",
              " 'amp',\n",
              " 'jacinta',\n",
              " 'secret',\n",
              " '2k13',\n",
              " 'fallen',\n",
              " 'skies',\n",
              " 'edit',\n",
              " 'mar',\n",
              " '30',\n",
              " '2013',\n",
              " 'httpstco7mlmsuzv1z',\n",
              " 'navista7',\n",
              " 'steve',\n",
              " 'fires',\n",
              " 'here',\n",
              " 'something',\n",
              " 'else',\n",
              " 'tinderbox',\n",
              " 'clown',\n",
              " 'hood',\n",
              " 'news24680',\n",
              " 'nowplaying',\n",
              " 'ian',\n",
              " 'buff',\n",
              " 'magnitude',\n",
              " 'httptcoav2jsjfftc',\n",
              " 'edm',\n",
              " 'nxwestmidlands',\n",
              " 'huge',\n",
              " 'httptcorwzbfvnxer',\n",
              " 'does',\n",
              " 'talk',\n",
              " 'go',\n",
              " 'until',\n",
              " 'dont',\n",
              " 'make',\n",
              " 'work',\n",
              " 'kids',\n",
              " 'cuz',\n",
              " 'bicycle',\n",
              " 'accident',\n",
              " 'split',\n",
              " 'testicles',\n",
              " 'impossible',\n",
              " 'michael',\n",
              " 'father',\n",
              " 'i24',\n",
              " 'w',\n",
              " 'nashvilletraffic',\n",
              " 'traffic',\n",
              " 'moving',\n",
              " '8m',\n",
              " 'slower',\n",
              " 'than',\n",
              " 'usual',\n",
              " 'httpstco0ghk693egj',\n",
              " 'center',\n",
              " 'lane',\n",
              " 'blocked',\n",
              " 'santaclara',\n",
              " 'us101',\n",
              " 'nb',\n",
              " 'great',\n",
              " 'america',\n",
              " 'pkwy',\n",
              " 'bayarea',\n",
              " 'httptcopmlohzurwr',\n",
              " 'httptcogkye6gjtk5',\n",
              " 'personalinjury',\n",
              " 'read',\n",
              " 'advice',\n",
              " 'solicitor',\n",
              " 'help',\n",
              " 'otleyhour',\n",
              " 'stlouis',\n",
              " 'caraccidentlawyer',\n",
              " 'speeding',\n",
              " 'among',\n",
              " 'teen',\n",
              " 'accidents',\n",
              " 'httpstcok4zomof319',\n",
              " 'httpstcos2kxvm0cba',\n",
              " 'tee\\x89',\n",
              " 'reported',\n",
              " 'motor',\n",
              " 'vehicle',\n",
              " 'curry',\n",
              " 'herman',\n",
              " 'rd',\n",
              " 'stephenson',\n",
              " 'involving',\n",
              " 'overturned',\n",
              " 'please',\n",
              " 'use',\n",
              " 'httptcoybjezkurw1',\n",
              " 'bigrigradio',\n",
              " 'awareness',\n",
              " 'i77',\n",
              " 'mile',\n",
              " 'marker',\n",
              " '31',\n",
              " 'mooresville',\n",
              " 'iredell',\n",
              " 'ramp',\n",
              " '86',\n",
              " '118',\n",
              " 'pm',\n",
              " 'sleepjunkies',\n",
              " 'sleeping',\n",
              " 'pills',\n",
              " 'double',\n",
              " 'risk',\n",
              " 'httptco7s9nm1fict',\n",
              " 'knew',\n",
              " 'gon',\n",
              " 'happen',\n",
              " 'httpstcoysxun5vceh',\n",
              " 'n',\n",
              " 'cabrillo',\n",
              " 'hwymagellan',\n",
              " 'av',\n",
              " 'mir',\n",
              " '080615',\n",
              " '110358',\n",
              " '40',\n",
              " 'congestion',\n",
              " 'pastor',\n",
              " 'scene',\n",
              " 'accidentwho',\n",
              " 'owner',\n",
              " 'range',\n",
              " 'rover',\n",
              " 'mom',\n",
              " 'didnt',\n",
              " 'wished',\n",
              " 'why',\n",
              " 'there',\n",
              " 'some',\n",
              " 'spilt',\n",
              " 'mayonnaise',\n",
              " 'over',\n",
              " 'horrible',\n",
              " 'past',\n",
              " 'sunday',\n",
              " 'finally',\n",
              " 'able',\n",
              " 'thank',\n",
              " 'god',\n",
              " 'pissed',\n",
              " 'donnie',\n",
              " 'when',\n",
              " 'tell',\n",
              " 'him',\n",
              " 'another',\n",
              " 'truckcrash',\n",
              " 'overturns',\n",
              " 'fortworth',\n",
              " 'interstate',\n",
              " 'httptcors22lj4qfp',\n",
              " 'click',\n",
              " 'youve',\n",
              " 'been',\n",
              " 'crashgthttptcold0uniyw4k',\n",
              " 'ashville',\n",
              " '23',\n",
              " 'sb',\n",
              " 'sr',\n",
              " '752',\n",
              " 'httptcohylmo0wgfi',\n",
              " 'carolina',\n",
              " 'motorcyclist',\n",
              " 'dies',\n",
              " 'i540',\n",
              " 'crossed',\n",
              " 'median',\n",
              " 'motorcycle',\n",
              " 'rider',\n",
              " 'traveling',\n",
              " 'httptcop18lzrlmy6',\n",
              " 'fyi',\n",
              " 'cadfyi',\n",
              " 'property',\n",
              " 'damagenhs999',\n",
              " 'piner',\n",
              " 'rdhorndale',\n",
              " 'dr',\n",
              " 'naayf',\n",
              " 'turning',\n",
              " 'onto',\n",
              " 'chandanee',\n",
              " 'magu',\n",
              " 'mma',\n",
              " 'taxi',\n",
              " 'rammed',\n",
              " 'halfway',\n",
              " 'turned',\n",
              " 'everyone',\n",
              " 'conf\\x89',\n",
              " 'left',\n",
              " 'manchester',\n",
              " '293',\n",
              " 'eddy',\n",
              " 'stop',\n",
              " 'back',\n",
              " 'nh3a',\n",
              " 'delay',\n",
              " '4',\n",
              " 'mins',\n",
              " 'httptcooia5fxi4gm',\n",
              " 'damagewpd1600',\n",
              " 's',\n",
              " '17th',\n",
              " '862015209',\n",
              " 'injury',\n",
              " '2781',\n",
              " 'willis',\n",
              " 'foreman',\n",
              " 'httptcovckit6edev',\n",
              " 'aashiqui',\n",
              " 'actress',\n",
              " 'anu',\n",
              " 'aggarwal',\n",
              " 'her',\n",
              " 'nearfatal',\n",
              " 'httptco6otfp31lqw',\n",
              " 'suffield',\n",
              " 'alberta',\n",
              " 'httpstcobptmlf4p10',\n",
              " '9',\n",
              " 'backup',\n",
              " 'southaccident',\n",
              " 'blocking',\n",
              " 'right',\n",
              " '2',\n",
              " 'lanes',\n",
              " 'exit',\n",
              " 'langtree',\n",
              " 'rdconsider',\n",
              " 'nc',\n",
              " '115',\n",
              " '150',\n",
              " '16',\n",
              " 'alternate',\n",
              " 'changed',\n",
              " 'determine',\n",
              " 'options',\n",
              " 'financially',\n",
              " 'support',\n",
              " 'plans',\n",
              " 'ongoing',\n",
              " 'treatment',\n",
              " 'deadly',\n",
              " 'happened',\n",
              " 'hagerstown',\n",
              " 'today',\n",
              " 'ill',\n",
              " 'details',\n",
              " '5',\n",
              " 'your4state',\n",
              " 'whag',\n",
              " 'flowri',\n",
              " 'were',\n",
              " 'marinading',\n",
              " 'only',\n",
              " 'even',\n",
              " 'fucking',\n",
              " 'mfs',\n",
              " 'drive',\n",
              " 'norwaymfa',\n",
              " 'bahrain',\n",
              " 'previously',\n",
              " 'road',\n",
              " 'killed',\n",
              " 'explosion',\n",
              " 'httpstcogfjfgtodad',\n",
              " 'still',\n",
              " 'heard',\n",
              " 'leaders',\n",
              " 'kenya',\n",
              " 'forward',\n",
              " 'comment',\n",
              " 'issue',\n",
              " 'disciplinary',\n",
              " 'measuresarrestpastornganga',\n",
              " 'aftershockdelo',\n",
              " 'scuf',\n",
              " 'ps',\n",
              " 'game',\n",
              " 'cya',\n",
              " 'who',\n",
              " 'himself',\n",
              " 'further',\n",
              " 'once',\n",
              " 'effort',\n",
              " 'gets',\n",
              " 'painful',\n",
              " 'win',\n",
              " 'roger',\n",
              " 'bannister',\n",
              " '320',\n",
              " 'ir',\n",
              " 'icemoon',\n",
              " 'aftershock',\n",
              " 'httptcoynxnvvkcda',\n",
              " 'djicemoon',\n",
              " 'dubstep',\n",
              " 'trapmusic',\n",
              " 'dnb',\n",
              " 'dance',\n",
              " 'ices\\x89',\n",
              " 'httptcoweqpesenku',\n",
              " 'victory',\n",
              " 'bargain',\n",
              " 'basement',\n",
              " 'prices',\n",
              " 'dwight',\n",
              " 'david',\n",
              " 'eisenhower',\n",
              " 'nobody',\n",
              " 'remembers',\n",
              " 'came',\n",
              " 'charles',\n",
              " 'schulz',\n",
              " 'speaking',\n",
              " 'someone',\n",
              " 'using',\n",
              " 'xb1',\n",
              " 'most',\n",
              " 'also',\n",
              " 'harder',\n",
              " 'conflict',\n",
              " 'glorious',\n",
              " 'triumph',\n",
              " 'thomas',\n",
              " 'paine',\n",
              " 'growingupspoiled',\n",
              " 'going',\n",
              " 'clay',\n",
              " 'pigeon',\n",
              " 'shooting',\n",
              " 'because',\n",
              " 'guess',\n",
              " 'one',\n",
              " 'actually',\n",
              " 'wants',\n",
              " 'any',\n",
              " 'free',\n",
              " 'tc',\n",
              " 'terrifying',\n",
              " 'best',\n",
              " 'roller',\n",
              " 'coaster',\n",
              " 'ever',\n",
              " 'disclaimer',\n",
              " 'very',\n",
              " 'few',\n",
              " 'httpstcoxmwodfmtui',\n",
              " 'kjfordays',\n",
              " 'seeing',\n",
              " 'issues',\n",
              " 'wisdomwed',\n",
              " 'bonus',\n",
              " 'minute',\n",
              " 'daily',\n",
              " 'habits',\n",
              " 'could',\n",
              " 'really',\n",
              " 'improve',\n",
              " 'many',\n",
              " 'already',\n",
              " 'lifehacks',\n",
              " 'httptcotbm9fqb8cw',\n",
              " 'protect',\n",
              " 'yourself',\n",
              " 'profit',\n",
              " 'global',\n",
              " 'financial',\n",
              " 'meltdown',\n",
              " 'wiedemer',\n",
              " 'http',\n",
              " 'httptcowztz4hgmvq',\n",
              " 'moment',\n",
              " 'scary',\n",
              " 'guy',\n",
              " 'behind',\n",
              " 'screaming',\n",
              " 'bloody',\n",
              " 'murder',\n",
              " 'silverwood',\n",
              " '\\x89',\n",
              " '2010',\n",
              " 'full\\x89',\n",
              " 'streaming',\n",
              " 'youtube',\n",
              " 'httptcovve3usesgf',\n",
              " 'gtgt',\n",
              " '15',\n",
              " 'book',\n",
              " 'httptcof6ntuc734z',\n",
              " 'esquireattire',\n",
              " 'sometimes',\n",
              " 'face',\n",
              " 'difficulties',\n",
              " 'doing',\n",
              " 'wrong',\n",
              " 'joel',\n",
              " 'osteen',\n",
              " 'thing',\n",
              " 'stands',\n",
              " 'between',\n",
              " 'dream',\n",
              " 'belief',\n",
              " 'possible',\n",
              " 'brown',\n",
              " 'praise',\n",
              " 'ministry',\n",
              " 'tells',\n",
              " 'wdyouth',\n",
              " 'biblestudy',\n",
              " 'httpstcoujk0e5gbcc',\n",
              " 'remembering',\n",
              " 'die',\n",
              " 'way',\n",
              " 'avoid',\n",
              " 'trap',\n",
              " 'thinking',\n",
              " 'lose',\n",
              " 'jobs',\n",
              " 'tried',\n",
              " 'orange',\n",
              " 'never',\n",
              " 'same',\n",
              " 'onfireanders',\n",
              " 'bb',\n",
              " 'httpstcojv8ppkhjy7',\n",
              " 'kick',\n",
              " 'off',\n",
              " 'want',\n",
              " 'making',\n",
              " 'say',\n",
              " 'cannot',\n",
              " 'done',\n",
              " 'should',\n",
              " 'interrupt',\n",
              " 'those',\n",
              " 'george',\n",
              " 'bernard',\n",
              " 'shaw',\n",
              " 'oyster',\n",
              " 'shell',\n",
              " 'andrew',\n",
              " 'carnegie',\n",
              " 'anyone',\n",
              " 'need',\n",
              " 'pu',\n",
              " 'play',\n",
              " 'hybrid',\n",
              " 'slayer',\n",
              " 'ps4',\n",
              " 'eu',\n",
              " 'hmu',\n",
              " 'cod8sandscrims',\n",
              " 'empirikgaming',\n",
              " 'codawscrims',\n",
              " '4tpkotc',\n",
              " '4tpfa',\n",
              " 'aftershockorg',\n",
              " 'experts',\n",
              " 'france',\n",
              " 'begin',\n",
              " 'examining',\n",
              " 'airplane',\n",
              " 'debris',\n",
              " 'found',\n",
              " 'reunion',\n",
              " 'island',\n",
              " 'french',\n",
              " 'air',\n",
              " 'o',\n",
              " 'httptcoyvvpznzmxg',\n",
              " 'news',\n",
              " 'strict',\n",
              " 'liability',\n",
              " 'context',\n",
              " 'pilot',\n",
              " 'error',\n",
              " 'common',\n",
              " 'component',\n",
              " 'aviation',\n",
              " 'cr',\n",
              " 'httptco6cz3bohrd4',\n",
              " 'crobscarla',\n",
              " 'lifetime',\n",
              " 'odds',\n",
              " 'dying',\n",
              " '1',\n",
              " '8015',\n",
              " 'wedn',\n",
              " 'httptcobkpfpogysi',\n",
              " 'alexalltimelow',\n",
              " 'awwww',\n",
              " 'theyre',\n",
              " 'cuties',\n",
              " 'good',\n",
              " 'job',\n",
              " 'family',\n",
              " 'members',\n",
              " 'osama',\n",
              " 'bin',\n",
              " 'laden',\n",
              " 'ironic',\n",
              " 'mhmmm',\n",
              " 'gov',\n",
              " 'suspect',\n",
              " 'goes',\n",
              " 'engine',\n",
              " 'httptcotyjxrfd3st',\n",
              " 'via',\n",
              " 'wings',\n",
              " '29072015',\n",
              " 'httptcoi7kztevb2v',\n",
              " 'cessna',\n",
              " 'ocampo',\n",
              " 'coahuila',\n",
              " 'mexico',\n",
              " 'july',\n",
              " '29',\n",
              " '2015',\n",
              " 'four',\n",
              " 'men',\n",
              " 'including',\n",
              " 'state',\n",
              " 'government',\n",
              " 'official',\n",
              " 'watchthevideo',\n",
              " 'httptcop64xrvgjik',\n",
              " 'httptcolsmx2vwr3j',\n",
              " 'wednesday\\x89',\n",
              " 'wednesday',\n",
              " 'began',\n",
              " 't',\n",
              " 'kca',\n",
              " 'votejkt48id',\n",
              " 'mbataweel',\n",
              " 'rip',\n",
              " 'binladen',\n",
              " 'airplanes',\n",
              " 'almost',\n",
              " 'coworker',\n",
              " 'nudes',\n",
              " 'mode',\n",
              " 'mickinyman',\n",
              " 'theatlantic',\n",
              " 'might',\n",
              " 'wreck',\n",
              " 'politics',\n",
              " 'unbelievably',\n",
              " 'insane',\n",
              " 'airport',\n",
              " 'aircraft',\n",
              " 'aeroplane',\n",
              " 'runway',\n",
              " 'freaky\\x89',\n",
              " 'httpstcocezhq7czll',\n",
              " 'airplane29072015',\n",
              " 'httptcowq3wjsgphl',\n",
              " 'usama',\n",
              " 'ladins',\n",
              " 'naturally',\n",
              " 'plane',\n",
              " 'festival',\n",
              " 'httpstcokq9ae6ap2b',\n",
              " 'death',\n",
              " 'carfest',\n",
              " 'httptcogibyqhhkpk',\n",
              " 'dtn',\n",
              " 'brazil',\n",
              " 'exp',\n",
              " 'httptcom9ig3wq8lq',\n",
              " '\\x89airplane\\x89\\x9d',\n",
              " 'wtf',\n",
              " 'can\\x89t',\n",
              " 'believe',\n",
              " 'eyes',\n",
              " 'httptco6ffylajwps',\n",
              " 'nicole',\n",
              " 'fletcher',\n",
              " 'victim',\n",
              " 'crashed',\n",
              " 'times',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoPZxtE8XhwQ",
        "colab_type": "text"
      },
      "source": [
        "The following can be seen from the output above:\n",
        "\n",
        "- Many URLs\n",
        "- Many misspelled or elongated words\n",
        "- Many words combined without spaces (likely hashtags)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvElzdL5Y63E",
        "colab_type": "text"
      },
      "source": [
        "#### Spacing consistency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SdtNXqvZQsV",
        "colab_type": "text"
      },
      "source": [
        "This step merely attempts to resolve '\\n', '\\t' and extra spaces, by replacing them with a single space. The function used can be seen here:\n",
        "\n",
        "```\n",
        "def spacing(text):\n",
        "  text = text.replace(r'\\t', ' ')\n",
        "  text = text.replace(r'\\n', ' ')\n",
        "  text = text.replace(r\"\\s+\", \" \")\n",
        "  return text\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgUYtI8iY_NB",
        "colab_type": "code",
        "outputId": "07fc6098-ff01-4766-a6c8-aa4e4f61816a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "try_step(spacing)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:24<00:00, 80.67it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7600\n",
            "Previous baseline: \t 0.7606\n",
            "\u001b[31mReduction of: \t\t-0.0006\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq1YkDMaaCNh",
        "colab_type": "text"
      },
      "source": [
        "It appears that this step did not improve performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo7umDR8sIFz",
        "colab_type": "text"
      },
      "source": [
        "#### Simple standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoa1SybtZkiQ",
        "colab_type": "text"
      },
      "source": [
        "Here, basic standardization is done using the function below:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def standardize_text(text):\n",
        "  text = text.replace(r\"http\\S+\", \"\")\n",
        "  text = text.replace(r\"http\", \"\")\n",
        "  text = text.replace(r\"@\\S+\", \"\")\n",
        "  text = text.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
        "  text = text.replace(r\"@\", \"at \")\n",
        "  text = text.replace(r\"#\", \"hashtag \")\n",
        "  text = text.lower()\n",
        "  return text\n",
        "```\n",
        "\n",
        "With this function, URLs, user mentions, uncommon characters and hashtags are cleaned to ensure consistency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgrRDYFmqbi1",
        "colab_type": "code",
        "outputId": "cd62623b-3ad4-47d0-ac2d-ebb8c94f1573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "try_step(standardize_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:24<00:00, 80.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7577\n",
            "Previous baseline: \t 0.7606\n",
            "\u001b[31mReduction of: \t\t-0.0029\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDwSEiuW4DYs",
        "colab_type": "text"
      },
      "source": [
        "As expected, performance is uneffected by this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxV-r1Nbp7YE",
        "colab_type": "text"
      },
      "source": [
        "#### Remove \"\\x89..\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMC6jUhhq6Gg",
        "colab_type": "code",
        "outputId": "f7065e14-fd7b-4d90-dd66-e48f71483674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "try_step(replace_expression, expression = r'\\x89.+', replace_with = ' ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:26<00:00, 79.20it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7632\n",
            "Previous baseline: \t 0.7606\n",
            "\u001b[32mImprovement of: \t 0.0026\n",
            "\u001b[30m\n",
            "New baseline: \t\t 0.7632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aYzhCxnsIlK",
        "colab_type": "text"
      },
      "source": [
        "Removal of this expression along with everything that follows it appears to make performance worse.\n",
        "\n",
        "After some experimentation, we see that removal of the expression along with the two characters that follow it leads to the greatest improvement in performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYxAd1NRtGHV",
        "colab_type": "code",
        "outputId": "2116c4e1-839b-4cd6-b43a-051633378e10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "try_step(replace_expression, expression = r'\\x89..', replace_with = ' ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:26<00:00, 78.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7514\n",
            "Previous baseline: \t 0.7632\n",
            "\u001b[31mReduction of: \t\t-0.0118\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypu1oQCZvno_",
        "colab_type": "text"
      },
      "source": [
        "#### Retweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX-cr_TWzseX",
        "colab_type": "text"
      },
      "source": [
        "Next, we treat retweets by simply replacement the \"RT \" expression with \"\\_RT_\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-Ff8-p1vtIW",
        "colab_type": "code",
        "outputId": "ec96a6aa-f676-47c3-c7b9-048034446ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "try_step(replace_expression, expression = r'RT ', replace_with = '_RT_')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:24<00:00, 81.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7552\n",
            "Previous baseline: \t 0.7632\n",
            "\u001b[31mReduction of: \t\t-0.0080\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNxmikFM4e6h",
        "colab_type": "text"
      },
      "source": [
        "This change improves performance slightly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrsGW5e0_uz_",
        "colab_type": "text"
      },
      "source": [
        "#### Hashtags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChxUd1vo_x1H",
        "colab_type": "code",
        "outputId": "c903936a-2e99-4551-97dd-d32792bdfd48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "try_step(replace_expression, expression = hashtags['expression'], replace_with = hashtags['replacement'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:24<00:00, 80.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7521\n",
            "Previous baseline: \t 0.7632\n",
            "\u001b[31mReduction of: \t\t-0.0111\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTxcTTsczlQn",
        "colab_type": "text"
      },
      "source": [
        "#### Shorten elongated words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FrhVbQo0Nwu",
        "colab_type": "text"
      },
      "source": [
        "Here, we short words that have been elongated, such as `goooooooaaaaaal` and `coool`. However, we will not remove all duplicates of a letter. Rather, we will keep two versions of the repeated letters to get: `gooaal` and `cool`. As you can see, this is the appropriate action for the latter word, but not the former. We will try and resolve this with spell checking later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVpqgu5AzXpq",
        "colab_type": "code",
        "outputId": "2a38268d-1bce-4451-ffb3-376d2c88a327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "try_step(replace_expression, expression = lengthening['expression'], replace_with = lengthening['replacement'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:26<00:00, 79.06it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7560\n",
            "Previous baseline: \t 0.7632\n",
            "\u001b[31mReduction of: \t\t-0.0072\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow0Nf84C1GEO",
        "colab_type": "text"
      },
      "source": [
        "#### Remove special characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCLcb4aD1M76",
        "colab_type": "text"
      },
      "source": [
        "We saw in our word list that there are some non-ASCII characters with accents. We will try removing these here to see if performance improves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MTnfk1p07lK",
        "colab_type": "code",
        "outputId": "219ff084-3ef4-43c7-e4b2-98219472fd0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "try_step(remove_accented_chars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:24<00:00, 80.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7559\n",
            "Previous baseline: \t 0.7632\n",
            "\u001b[31mReduction of: \t\t-0.0073\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wbr8WPvrj1dk"
      },
      "source": [
        "#### Remove Stop Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LU5O57h868i",
        "colab_type": "text"
      },
      "source": [
        "Here, we look to remove stopwords. However, rather than simply removing a list of default stopwords blindly, we will **loop over each stop word** in a default list **and measure performance** after it has been removed. We will store the stopwords that should be removed in a list. This is done using the function defined previously and shown here.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def stopwords_to_remove(words, baseline, reference, vectorizer = 'basic', cv = cv, clf = clf, scoring = 'f1', random_state = rs):\n",
        "  stop = []\n",
        "  i = 1\n",
        "\n",
        "  for word in words:\n",
        "    stop.append(word)\n",
        "    train['temp'] = reference.apply(remove_stopwords, words = stop)\n",
        "\n",
        "    if vectorizer == 'universal':\n",
        "      X_temp = []\n",
        "    \n",
        "      for r in tqdm(train['temp'].values):\n",
        "        emb = use(r)\n",
        "        review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "        X_temp.append(review_emb)\n",
        "\n",
        "      X_temp = np.array(X_temp)\n",
        "      y_train = train['target'].values\n",
        "      X, test_arrays, y, test_labels = train_test_split(X_temp, y_train, random_state = random_state, test_size = 0.3)\n",
        "      score = cross_val_score(clf, X, y, cv = cv, scoring = scoring).mean()\n",
        "\n",
        "    if vectorizer == 'basic':\n",
        "      X, X_t, y, y_t = train_test_split(train['temp'], train['target'], random_state = random_state)\n",
        "      X = tfidf.fit_transform(X)\n",
        "      score = cross_val_score(clf, X, y, cv = cv, scoring = scoring).mean()\n",
        "    \n",
        "    \n",
        "    print(\"{}%\\t\".format(np.round((i/len(all_stopwords)*100), 2)), np.round(score, 4),'    \\t', stop)\n",
        "    i += 1\n",
        "\n",
        "    if score > baseline:\n",
        "      baseline = score\n",
        "      reference = reference.apply(remove_stopwords, words = stop)\n",
        "      \n",
        "    else:\n",
        "      stop.remove(word)\n",
        "  \n",
        "  print('\\nSelected stopwords to remove:\\n', stop)\n",
        "  return stop\n",
        "```\n",
        "<br>\n",
        "\n",
        "The function's required arguments include:\n",
        "- **words**, which is the list of stopwords that will be looped over.\n",
        "- **baseline**, which is the baseline score that the function is trying to improve upon.\n",
        "- **reference**, which is the column that contains the text from which the stop words should be removed.\n",
        "\n",
        "<br>\n",
        "\n",
        "The function returns a list of words that should be removed to improve performance, if one exists.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "The downside of this approach, however, is that it fails to capture the optimal combination, as some words may improve performance when removed together, but not when removed independently. To combat this, we will run the loop multiple times. By doing so, we should capture the most impactful words initially, followed by other words that improve performance when combined with the more impactful words.\n",
        "\n",
        "<br>\n",
        "\n",
        "An additional downside is that this approach takes a very long time. In order to reduce the training time, we won't use the **universal word embeddings**, but rather the **Tfidf Vectorizer** for creating vectors. This approach, though, will produce lower scores. Therefore, an artificial baseline is hard-coded so that the algorithm has something achievable to target and attempt to surpass. Once the stop words are selected, they will be removed all together and the result will be measured using our original approach with the **universal word embeddings**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY0QbQ-znakm",
        "colab_type": "code",
        "outputId": "498afe0e-97fa-4182-f541-bd02f09ceea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "all_words = get_words(train[reference]) # get words in processed_text column\n",
        "all_stopwords = [x for x in stopwords.words('english') if x in all_words] # create list of words in interesection of all_words and default list of stopwords\n",
        "best_score = 0.71 # hard-coded baseline\n",
        "\n",
        "stop = stopwords_to_remove(words = all_stopwords, baseline = best_score, reference = train[reference])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.75%\t 0.6979     \t ['i']\n",
            "1.49%\t 0.6875     \t ['me']\n",
            "2.24%\t 0.6841     \t ['my']\n",
            "2.99%\t 0.7005     \t ['myself']\n",
            "4.48%\t 0.6906     \t ['our']\n",
            "5.22%\t 0.7091     \t ['ourselves']\n",
            "5.97%\t 0.6849     \t ['you']\n",
            "6.72%\t 0.6919     \t ['your']\n",
            "7.46%\t 0.6857     \t ['yours']\n",
            "8.21%\t 0.7045     \t ['yourself']\n",
            "8.96%\t 0.691     \t ['yourselves']\n",
            "9.7%\t 0.7008     \t ['he']\n",
            "10.45%\t 0.6883     \t ['him']\n",
            "11.19%\t 0.7109     \t ['his']\n",
            "11.94%\t 0.7134     \t ['his', 'himself']\n",
            "12.69%\t 0.708     \t ['his', 'himself', 'she']\n",
            "13.43%\t 0.6906     \t ['his', 'himself', 'her']\n",
            "14.18%\t 0.7053     \t ['his', 'himself', 'herself']\n",
            "14.93%\t 0.7024     \t ['his', 'himself', 'it']\n",
            "15.67%\t 0.7101     \t ['his', 'himself', 'its']\n",
            "16.42%\t 0.7051     \t ['his', 'himself', 'itself']\n",
            "17.16%\t 0.6974     \t ['his', 'himself', 'they']\n",
            "17.91%\t 0.7135     \t ['his', 'himself', 'them']\n",
            "18.66%\t 0.6976     \t ['his', 'himself', 'them', 'their']\n",
            "19.4%\t 0.6996     \t ['his', 'himself', 'them', 'theirs']\n",
            "20.15%\t 0.6967     \t ['his', 'himself', 'them', 'themselves']\n",
            "20.9%\t 0.6993     \t ['his', 'himself', 'them', 'what']\n",
            "21.64%\t 0.6992     \t ['his', 'himself', 'them', 'which']\n",
            "22.39%\t 0.7056     \t ['his', 'himself', 'them', 'who']\n",
            "23.13%\t 0.6805     \t ['his', 'himself', 'them', 'this']\n",
            "23.88%\t 0.7025     \t ['his', 'himself', 'them', 'that']\n",
            "24.63%\t 0.7065     \t ['his', 'himself', 'them', 'these']\n",
            "25.37%\t 0.7085     \t ['his', 'himself', 'them', 'those']\n",
            "26.12%\t 0.6712     \t ['his', 'himself', 'them', 'am']\n",
            "26.87%\t 0.7009     \t ['his', 'himself', 'them', 'is']\n",
            "27.61%\t 0.6994     \t ['his', 'himself', 'them', 'are']\n",
            "28.36%\t 0.6889     \t ['his', 'himself', 'them', 'was']\n",
            "29.1%\t 0.7043     \t ['his', 'himself', 'them', 'were']\n",
            "29.85%\t 0.7018     \t ['his', 'himself', 'them', 'be']\n",
            "30.6%\t 0.6864     \t ['his', 'himself', 'them', 'been']\n",
            "31.34%\t 0.7125     \t ['his', 'himself', 'them', 'being']\n",
            "32.09%\t 0.707     \t ['his', 'himself', 'them', 'have']\n",
            "32.84%\t 0.699     \t ['his', 'himself', 'them', 'has']\n",
            "33.58%\t 0.7015     \t ['his', 'himself', 'them', 'had']\n",
            "34.33%\t 0.7065     \t ['his', 'himself', 'them', 'having']\n",
            "35.07%\t 0.7018     \t ['his', 'himself', 'them', 'do']\n",
            "35.82%\t 0.701     \t ['his', 'himself', 'them', 'does']\n",
            "36.57%\t 0.6605     \t ['his', 'himself', 'them', 'did']\n",
            "37.31%\t 0.708     \t ['his', 'himself', 'them', 'doing']\n",
            "38.06%\t 0.709     \t ['his', 'himself', 'them', 'a']\n",
            "38.81%\t 0.7106     \t ['his', 'himself', 'them', 'an']\n",
            "39.55%\t 0.7052     \t ['his', 'himself', 'them', 'the']\n",
            "40.3%\t 0.6977     \t ['his', 'himself', 'them', 'and']\n",
            "41.04%\t 0.705     \t ['his', 'himself', 'them', 'but']\n",
            "41.79%\t 0.6919     \t ['his', 'himself', 'them', 'if']\n",
            "42.54%\t 0.7069     \t ['his', 'himself', 'them', 'or']\n",
            "43.28%\t 0.6798     \t ['his', 'himself', 'them', 'because']\n",
            "44.03%\t 0.7042     \t ['his', 'himself', 'them', 'as']\n",
            "44.78%\t 0.7087     \t ['his', 'himself', 'them', 'until']\n",
            "45.52%\t 0.6964     \t ['his', 'himself', 'them', 'while']\n",
            "46.27%\t 0.7111     \t ['his', 'himself', 'them', 'of']\n",
            "47.01%\t 0.7001     \t ['his', 'himself', 'them', 'at']\n",
            "47.76%\t 0.6857     \t ['his', 'himself', 'them', 'by']\n",
            "48.51%\t 0.6899     \t ['his', 'himself', 'them', 'for']\n",
            "49.25%\t 0.6892     \t ['his', 'himself', 'them', 'with']\n",
            "50.0%\t 0.7017     \t ['his', 'himself', 'them', 'about']\n",
            "50.75%\t 0.7014     \t ['his', 'himself', 'them', 'against']\n",
            "51.49%\t 0.6962     \t ['his', 'himself', 'them', 'between']\n",
            "52.24%\t 0.7033     \t ['his', 'himself', 'them', 'into']\n",
            "52.99%\t 0.682     \t ['his', 'himself', 'them', 'through']\n",
            "53.73%\t 0.7024     \t ['his', 'himself', 'them', 'during']\n",
            "54.48%\t 0.6929     \t ['his', 'himself', 'them', 'before']\n",
            "55.22%\t 0.7082     \t ['his', 'himself', 'them', 'after']\n",
            "55.97%\t 0.7017     \t ['his', 'himself', 'them', 'above']\n",
            "56.72%\t 0.7019     \t ['his', 'himself', 'them', 'below']\n",
            "57.46%\t 0.6875     \t ['his', 'himself', 'them', 'to']\n",
            "58.21%\t 0.6916     \t ['his', 'himself', 'them', 'from']\n",
            "58.96%\t 0.7009     \t ['his', 'himself', 'them', 'up']\n",
            "59.7%\t 0.6859     \t ['his', 'himself', 'them', 'down']\n",
            "60.45%\t 0.6704     \t ['his', 'himself', 'them', 'in']\n",
            "61.19%\t 0.704     \t ['his', 'himself', 'them', 'out']\n",
            "61.94%\t 0.6935     \t ['his', 'himself', 'them', 'on']\n",
            "62.69%\t 0.6834     \t ['his', 'himself', 'them', 'off']\n",
            "63.43%\t 0.7056     \t ['his', 'himself', 'them', 'over']\n",
            "64.18%\t 0.7007     \t ['his', 'himself', 'them', 'under']\n",
            "64.93%\t 0.7024     \t ['his', 'himself', 'them', 'again']\n",
            "65.67%\t 0.706     \t ['his', 'himself', 'them', 'further']\n",
            "66.42%\t 0.7022     \t ['his', 'himself', 'them', 'then']\n",
            "67.16%\t 0.6932     \t ['his', 'himself', 'them', 'once']\n",
            "67.91%\t 0.6986     \t ['his', 'himself', 'them', 'here']\n",
            "68.66%\t 0.6921     \t ['his', 'himself', 'them', 'there']\n",
            "69.4%\t 0.6865     \t ['his', 'himself', 'them', 'when']\n",
            "70.15%\t 0.7022     \t ['his', 'himself', 'them', 'where']\n",
            "70.9%\t 0.7118     \t ['his', 'himself', 'them', 'why']\n",
            "71.64%\t 0.6933     \t ['his', 'himself', 'them', 'how']\n",
            "72.39%\t 0.6921     \t ['his', 'himself', 'them', 'all']\n",
            "73.13%\t 0.6745     \t ['his', 'himself', 'them', 'any']\n",
            "73.88%\t 0.7057     \t ['his', 'himself', 'them', 'both']\n",
            "74.63%\t 0.686     \t ['his', 'himself', 'them', 'each']\n",
            "75.37%\t 0.6906     \t ['his', 'himself', 'them', 'few']\n",
            "76.12%\t 0.7077     \t ['his', 'himself', 'them', 'more']\n",
            "76.87%\t 0.6975     \t ['his', 'himself', 'them', 'most']\n",
            "77.61%\t 0.6868     \t ['his', 'himself', 'them', 'other']\n",
            "78.36%\t 0.6923     \t ['his', 'himself', 'them', 'some']\n",
            "79.1%\t 0.7124     \t ['his', 'himself', 'them', 'such']\n",
            "79.85%\t 0.6866     \t ['his', 'himself', 'them', 'no']\n",
            "80.6%\t 0.7088     \t ['his', 'himself', 'them', 'nor']\n",
            "81.34%\t 0.6674     \t ['his', 'himself', 'them', 'not']\n",
            "82.09%\t 0.7107     \t ['his', 'himself', 'them', 'only']\n",
            "82.84%\t 0.6908     \t ['his', 'himself', 'them', 'own']\n",
            "83.58%\t 0.6966     \t ['his', 'himself', 'them', 'same']\n",
            "84.33%\t 0.689     \t ['his', 'himself', 'them', 'so']\n",
            "85.07%\t 0.697     \t ['his', 'himself', 'them', 'than']\n",
            "85.82%\t 0.7096     \t ['his', 'himself', 'them', 'too']\n",
            "86.57%\t 0.7125     \t ['his', 'himself', 'them', 'very']\n",
            "87.31%\t 0.7057     \t ['his', 'himself', 'them', 's']\n",
            "88.06%\t 0.6957     \t ['his', 'himself', 'them', 't']\n",
            "88.81%\t 0.7086     \t ['his', 'himself', 'them', 'can']\n",
            "89.55%\t 0.7021     \t ['his', 'himself', 'them', 'will']\n",
            "90.3%\t 0.7094     \t ['his', 'himself', 'them', 'just']\n",
            "91.04%\t 0.7063     \t ['his', 'himself', 'them', 'don']\n",
            "91.79%\t 0.6987     \t ['his', 'himself', 'them', 'should']\n",
            "92.54%\t 0.7054     \t ['his', 'himself', 'them', 'now']\n",
            "93.28%\t 0.6989     \t ['his', 'himself', 'them', 'd']\n",
            "94.03%\t 0.7002     \t ['his', 'himself', 'them', 'm']\n",
            "94.78%\t 0.7018     \t ['his', 'himself', 'them', 'o']\n",
            "95.52%\t 0.6913     \t ['his', 'himself', 'them', 're']\n",
            "96.27%\t 0.6929     \t ['his', 'himself', 'them', 've']\n",
            "97.01%\t 0.6994     \t ['his', 'himself', 'them', 'y']\n",
            "97.76%\t 0.7056     \t ['his', 'himself', 'them', 'didn']\n",
            "98.51%\t 0.7059     \t ['his', 'himself', 'them', 'ma']\n",
            "99.25%\t 0.7085     \t ['his', 'himself', 'them', 'won']\n",
            "100.0%\t 0.7022     \t ['his', 'himself', 'them', 'wouldn']\n",
            "\n",
            "Selected stopwords to remove:\n",
            " ['his', 'himself', 'them']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbaEp5PZsgbc",
        "colab_type": "text"
      },
      "source": [
        "As we see from the output above, the removal of some words improves performance, while the removal of others worsens it. Thus, the approach taken here was the appropriate one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "43fe46ac-3377-450b-f43c-41234e7a0739",
        "id": "WzUni_gtj1dp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# stop = ['his', 'himself', 'them']\n",
        "try_step(remove_stopwords, words = stop)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:24<00:00, 80.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7590\n",
            "Previous baseline: \t 0.7632\n",
            "\u001b[31mReduction of: \t\t-0.0042\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq9LeMHK8Faw",
        "colab_type": "text"
      },
      "source": [
        "Despite our efforts, removal of the selected stop words didn't improve the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NRFr5Basx1VH"
      },
      "source": [
        "#### Strip HTML tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLfzuZZw19Cm",
        "colab_type": "text"
      },
      "source": [
        "Here, we will strip HTML tags from the tweets.  Though not likely to be present in a lot of tweets, HTML tags may be present. Some tags that might be present include:\n",
        "\n",
        "- \\<html> ... \\</html>\n",
        "- \\<head> ... \\</head>\n",
        "- \\<title> ... \\</title>\n",
        "- \\<body> ... \\</body>\n",
        "- \\<p> ... \\</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwCMoVaYv9Sg",
        "colab_type": "code",
        "outputId": "622e04f0-38d9-4813-d6d0-68ddf43d0a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "try_step(strip_html_tags)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:25<00:00, 80.01it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7491\n",
            "Previous baseline: \t 0.7632\n",
            "\u001b[31mReduction of: \t\t-0.0141\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPhth2yI5iL_",
        "colab_type": "text"
      },
      "source": [
        "#### Replace emojis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSGzqRwS5kbb",
        "colab_type": "text"
      },
      "source": [
        "Here we use a regex to find and replace emojis with an empty space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm82IqtC5Ixk",
        "colab_type": "code",
        "outputId": "351654ea-51d6-436a-d5e0-9a6a72a4a6bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "try_step(replace_expression, expression = emojis['expression'], replace_with = emojis['replacement'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:25<00:00, 80.06it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7548\n",
            "Previous baseline: \t 0.7632\n",
            "\u001b[31mReduction of: \t\t-0.0085\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQMOePQY5oyl",
        "colab_type": "text"
      },
      "source": [
        "It appears that this has no effect. This is likely a result of emojis not translating over to our dataframe. However, it was worth the attempt to confirm the suspicion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyAwhGDB669U",
        "colab_type": "text"
      },
      "source": [
        "#### Remove numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxI0mznu68w4",
        "colab_type": "text"
      },
      "source": [
        "Here, we attempt to remove numbers to see if performance improves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RDDjm2G6hCs",
        "colab_type": "code",
        "outputId": "91f001ca-8079-4a0a-f43f-84ab028852ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "try_step(replace_expression, expression = r\"[0-9]\", replace_with = '')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:24<00:00, 80.79it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7565\n",
            "Previous baseline: \t 0.7632\n",
            "\u001b[31mReduction of: \t\t-0.0067\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0H5JYvhTx1VJ"
      },
      "source": [
        "#### Expand contracted words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H-C5UIVd7Fd",
        "colab_type": "text"
      },
      "source": [
        "Using a similar approach to the removal of stop words, each word in the intersection of the `CONTRACTION_MAP` dictionary and `all_words` is expanded in a loop. The change in performance is measured, and all contractions that improve performance are stored to be expanded in the following step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjxZa7Z9wPhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all_contractions = {}\n",
        "# all_words = get_words(train[reference])\n",
        "# best_score = 0.71\n",
        "\n",
        "# for k, v in CONTRACTION_MAP.items():\n",
        "#   if k in all_words:\n",
        "#     all_contractions[k] = v\n",
        "\n",
        "# contractions = contractions_to_expand(words = all_contractions, baseline = best_score, reference=train[reference])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5_nJq-kwjoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if len(contractions) > 0:\n",
        "#   try_step(expand_contractions, contraction_mapping = contractions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lijrlold-ZN6",
        "colab_type": "text"
      },
      "source": [
        "Expanding contractions proved not to improve performance. Therefore, this step has been commented out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JyiMLk7px1VK"
      },
      "source": [
        "#### Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGGORWfxelYv",
        "colab_type": "text"
      },
      "source": [
        "Here, stemming is applied to words. This step removes the ends of some words to get to their root. By doing so, words that are plurals or conjugations of the same word can be consolidated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsgpbCI5wrOP",
        "colab_type": "code",
        "outputId": "e2903f20-1636-4e99-a376-a6a7cc42d094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "try_step(stemming)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:24<00:00, 81.16it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7569\n",
            "Previous baseline: \t 0.7632\n",
            "\u001b[31mReduction of: \t\t-0.0064\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wN8XlNnYx1VL"
      },
      "source": [
        "#### Translate emoticons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "018oACNqev2Z",
        "colab_type": "text"
      },
      "source": [
        "Here, emoticons, such as `:)` and `:(` are translated into words. The first emoticon above would be relabelled \"\\_HAPPY_\" and the latter \"\\_SAD_\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxIz1cFKw2HJ",
        "colab_type": "code",
        "outputId": "5e82921b-4179-4969-fe29-b452701ce20c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "try_step(emoticons)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:25<00:00, 80.31it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result: \t\t 0.7516\n",
            "Previous baseline: \t 0.7632\n",
            "\u001b[31mReduction of: \t\t-0.0116\n",
            "\u001b[30m\n",
            "Previous baseline remains the best.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QE81whUCx1VL"
      },
      "source": [
        "#### Replace abbreviations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQNapViqfDzG",
        "colab_type": "text"
      },
      "source": [
        "The dictionary of abbreviations is looped over in s a similar manner to the stop word removal and contraction expansion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfF-KMJlw_lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all_words = get_words(train[reference])\n",
        "# all_abbreviations = {}\n",
        "# best_score = 0.71\n",
        "\n",
        "# for k, v in abbreviations.items():\n",
        "#   if k in all_words:\n",
        "#     all_abbreviations[k] = v\n",
        "\n",
        "# abbr = abbreviations_to_replace(words = all_abbreviations, baseline = best_score, reference = train[reference])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYuYJ74Uw2OF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if len(abbr) > 0:\n",
        "#   try_step(convert_abbrev_in_text, words = abbr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AhoB8lbg-q8C"
      },
      "source": [
        "Replacing abbreviations, proved not to improve performance. Therefore, it has been commented out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PABLeugcxpNC"
      },
      "source": [
        "#### Remove punctuation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhE_hGdcftpP",
        "colab_type": "text"
      },
      "source": [
        "Punctuation is removed iteratively and performance is evaluated in a similar manner to the removal of stop words, expansion of contractions and replacement of abbreviations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHPJtOKZImMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# best_score = 0.71\n",
        "# punc = punct_to_remove(baseline = best_score, reference = train[reference])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1NFG4jVAxpNL",
        "colab": {}
      },
      "source": [
        "# if len(punc) > 0:\n",
        "#   try_step(remove_punct, punctuation = punc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEGxvNvo-ghR",
        "colab_type": "text"
      },
      "source": [
        "Removing punctuation, proved not to improve performance. Therefore, it has been commented out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE9mj4AWQxHD",
        "colab_type": "text"
      },
      "source": [
        "### Fine-tune and Validate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhSXqk1FQzyA",
        "colab_type": "text"
      },
      "source": [
        "#### Optimize parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pexwuwrof_Bm",
        "colab_type": "code",
        "outputId": "ad291ceb-1dc0-4e8b-9200-228f6cbe36c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = []\n",
        "for r in tqdm(train.text.values):\n",
        "  emb = use(r)\n",
        "  review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_train.append(review_emb)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = train.target.values\n",
        "\n",
        "X, test_arrays, y, test_labels = train_test_split(X_train, y_train, random_state = rs, test_size = 0.2)\n",
        "\n",
        "lr_model2 = lr_param_selection(X, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 6842/6842 [01:25<00:00, 80.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBCEWtFSlNXL",
        "colab_type": "code",
        "outputId": "68feff2d-a424-4e0c-c5bb-924a45104487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dump(lr_model2, 'lr_model2.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lr_model2.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDZVjXlPlPFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_model2 = load('lr_model2.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPBVx89WRcaF",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyT64-h_UkRV",
        "colab_type": "code",
        "outputId": "aa76d3d6-36e8-4785-e166-0d4ab2420471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "lr_pred = lr_model2.predict(test_arrays)\n",
        "print('LR Classifier\\n', classification_report(test_labels, lr_pred), '\\n'*2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR Classifier\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.88      0.84       808\n",
            "         1.0       0.80      0.69      0.74       561\n",
            "\n",
            "    accuracy                           0.80      1369\n",
            "   macro avg       0.80      0.78      0.79      1369\n",
            "weighted avg       0.80      0.80      0.80      1369\n",
            " \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc7KSgOmRpAv",
        "colab_type": "text"
      },
      "source": [
        "#### Pipeline for Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKrOEq0dUkg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test[reference] = test['text'].apply(lambda x: replace_expression(x, expression = r'\\x89.+', replace_with = ' '))\n",
        "# test[reference] = test[reference].apply(lambda x: strip_html_tags(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYAM3VAZlm_I",
        "colab_type": "code",
        "outputId": "2ff793ef-cbbb-47b9-9cab-41dcc54445b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test = []\n",
        "\n",
        "for r in tqdm(test[reference].values):\n",
        "  emb = use(r)\n",
        "  review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_test.append(review_emb)\n",
        "\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 3263/3263 [00:41<00:00, 79.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMCk_D57kzQh",
        "colab_type": "text"
      },
      "source": [
        "#### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onqLKJvTk08r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_pred = lr_model.predict(X_test)\n",
        "\n",
        "submission['target'] = lr_pred\n",
        "\n",
        "for k in similar_test.keys():\n",
        "  summation = submission.loc[similar_test[k],:]['target'].sum() + submission.loc[k,:]['target']\n",
        "  count = len(similar[k]) + 1\n",
        "  mean = summation/count\n",
        "  if mean > 0.5:\n",
        "    submission.loc[k,'target'] = 1\n",
        "    submission.loc[similar_test[k],'target'] = 1\n",
        "  else:\n",
        "    submission.loc[k,'target'] = 0\n",
        "    submission.loc[similar_test[k],'target'] = 0\n",
        "\n",
        "submission.to_csv('2_lr_submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGPW_7uuqR3T",
        "colab_type": "text"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzuFKGteitca",
        "colab_type": "text"
      },
      "source": [
        "## SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSWw0ohlNgYu",
        "colab_type": "text"
      },
      "source": [
        "This section was meant to follow a similar logic to the previous, however, the increased computational time and power required by the SVC model made the cost of training too high for the reward. However, the steps required are layed out and ready to be followed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XfW9lNCRKMe",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH5hOtoLixUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reference = 'processed_text_svc'\n",
        "train['processed_text_svc'] = train['text'].copy()\n",
        "clf = svc_model\n",
        "base = cross_val_score(clf, X, y, cv=cv, scoring=\"f1\").mean()\n",
        "baseline = base.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CLAlUtVcrQ0_"
      },
      "source": [
        "### Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FvtqI_7GrQ1F"
      },
      "source": [
        "#### Spacing consistency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KzGgbom9rQ1G",
        "colab": {}
      },
      "source": [
        "try_step(spacing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LrVYaVHTrQ1H"
      },
      "source": [
        "#### Simple standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9kqrY1UKrQ1I",
        "colab": {}
      },
      "source": [
        "try_step(standardize_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eLQegNoQrQ1K"
      },
      "source": [
        "#### Remove \"\\x89..\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Os7LRtYurQ1L",
        "colab": {}
      },
      "source": [
        "try_step(replace_expression, expression = r'\\x89..', replace_with = ' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mag6pEb0rQ1N"
      },
      "source": [
        "#### Retweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dm9xpuLjrQ1N",
        "colab": {}
      },
      "source": [
        "try_step(replace_expression, expression = r'RT ', replace_with = '_RT_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1PRvPv2LrQ1P"
      },
      "source": [
        "#### Hashtags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sKqoHo5ErQ1P",
        "colab": {}
      },
      "source": [
        "try_step(replace_expression, expression = hashtags['expression'], replace_with = hashtags['replacement'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WsT1aTWirQ1Q"
      },
      "source": [
        "#### Shorten elongated words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nTIHdTiErQ1R",
        "colab": {}
      },
      "source": [
        "try_step(replace_expression, expression = lengthening['expression'], replace_with = lengthening['replacement'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1fSaxfydrQ1S"
      },
      "source": [
        "#### Remove special characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zxpoNOyirQ1T",
        "colab": {}
      },
      "source": [
        "try_step(remove_accented_chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gjUsC6yarQ1U"
      },
      "source": [
        "#### Remove Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PTmxp3vtrQ1U",
        "colab": {}
      },
      "source": [
        "# all_words = get_words(train[reference]) # get words in processed_text column\n",
        "# all_stopwords = [x for x in stopwords.words('english') if x in all_words] # create list of words in interesection of all_words and default list of stopwords\n",
        "# best_score = 0.71 # hard-coded baseline\n",
        "\n",
        "# stop = stopwords_to_remove(words = all_stopwords, baseline = best_score, reference = train[reference])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6edTqAd3rQ1W",
        "colab": {}
      },
      "source": [
        "# try_step(remove_stopwords, words = stop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ftMBXdb6rQ1X"
      },
      "source": [
        "#### Strip HTML tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a_tuquJUrQ1Y",
        "colab": {}
      },
      "source": [
        "try_step(strip_html_tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2npDoV30rQ1Z"
      },
      "source": [
        "#### Replace emojis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F8cRnLvrrQ1Z",
        "colab": {}
      },
      "source": [
        "try_step(replace_expression, expression = emojis['expression'], replace_with = emojis['replacement'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UBIkBt_irQ1b"
      },
      "source": [
        "#### Remove numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qMp6OoiyrQ1b",
        "colab": {}
      },
      "source": [
        "try_step(replace_expression, expression = r\"[0-9]\", replace_with = '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lv5Qgp-xrQ1d"
      },
      "source": [
        "#### Expand contracted words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c4UKaMrtrQ1d",
        "colab": {}
      },
      "source": [
        "# all_contractions = {}\n",
        "# all_words = get_words(train[reference])\n",
        "# best_score = 0.71\n",
        "\n",
        "# for k, v in CONTRACTION_MAP.items():\n",
        "#   if k in all_words:\n",
        "#     all_contractions[k] = v\n",
        "\n",
        "# contractions = contractions_to_expand(words = all_contractions, baseline = best_score, reference=train[reference])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OdAM-0airQ1e",
        "colab": {}
      },
      "source": [
        "# if len(contractions) > 0:\n",
        "#   try_step(expand_contractions, contraction_mapping = contractions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mWNaI8q0rQ1f"
      },
      "source": [
        "#### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j7cNiW1hrQ1g",
        "colab": {}
      },
      "source": [
        "try_step(stemming)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_MoHKy17rQ1h"
      },
      "source": [
        "#### Translate emoticons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g5wzcU6qrQ1i",
        "colab": {}
      },
      "source": [
        "try_step(emoticons)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XUQxLnY9rQ1j"
      },
      "source": [
        "#### Replace abbreviations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "icIzUXK9rQ1k",
        "colab": {}
      },
      "source": [
        "# all_words = get_words(train[reference])\n",
        "# all_abbreviations = {}\n",
        "# best_score = 0.71\n",
        "\n",
        "# for k, v in abbreviations.items():\n",
        "#   if k in all_words:\n",
        "#     all_abbreviations[k] = v\n",
        "\n",
        "# abbr = abbreviations_to_replace(words = all_abbreviations, baseline = best_score, reference = train[reference])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n5zoop58rQ1l",
        "colab": {}
      },
      "source": [
        "# if len(abbr) > 0:\n",
        "#   try_step(convert_abbrev_in_text, words = abbr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z0ambU_WrQ1n"
      },
      "source": [
        "#### Remove punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HvGjkqccrQ1n",
        "colab": {}
      },
      "source": [
        "# best_score = 0.71\n",
        "# punc = punct_to_remove(baseline = best_score, reference = train[reference])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4JrTh3GtrQ1p",
        "colab": {}
      },
      "source": [
        "# if len(punc) > 0:\n",
        "#   try_step(remove_punct, punctuation = punc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qEGkkovMrQ1q"
      },
      "source": [
        "### Fine-tune and Validate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sn9aiMK9rQ1q"
      },
      "source": [
        "#### Optimize parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AQiAHerqrQ1q",
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "for r in tqdm(train.text.values):\n",
        "  emb = use(r)\n",
        "  review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_train.append(review_emb)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = train.target.values\n",
        "\n",
        "X, test_arrays, y, test_labels = train_test_split(X_train, y_train, random_state = rs, test_size = 0.2)\n",
        "\n",
        "lr_model2 = lr_param_selection(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zV5QtqxFrQ1r",
        "colab": {}
      },
      "source": [
        "dump(svc_model2, 'svc_model2.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S-iH-7H-rQ1t",
        "colab": {}
      },
      "source": [
        "svc_model2 = load('svc_model2.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4wi3wShTrQ1u"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VmvgedLprQ1u",
        "colab": {}
      },
      "source": [
        "svc_pred = svc_model2.predict(test_arrays)\n",
        "print('SVC\\n', classification_report(test_labels, svc_pred), '\\n'*2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Nyfzz0rrQ1w"
      },
      "source": [
        "#### Pipeline for Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XaR-6WUGrQ1w",
        "colab": {}
      },
      "source": [
        "# test[reference] = test['text'].apply(lambda x: remove_stopwords(x))\n",
        "# test[reference] = test[reference].apply(lambda x: strip_html_tags(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FEywn-OarQ1x",
        "colab": {}
      },
      "source": [
        "X_test = []\n",
        "\n",
        "for r in tqdm(test[reference].values):\n",
        "  emb = use(r)\n",
        "  review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_test.append(review_emb)\n",
        "\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Ez21d9prQ1z"
      },
      "source": [
        "#### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HiynAlw7rQ1z",
        "colab": {}
      },
      "source": [
        "svc_pred = svc_model2.predict(X_test)\n",
        "\n",
        "submission['target'] = svc_pred\n",
        "\n",
        "for k in similar_test.keys():\n",
        "  summation = submission.loc[similar_test[k],:]['target'].sum() + submission.loc[k,:]['target']\n",
        "  count = len(similar[k]) + 1\n",
        "  mean = summation/count\n",
        "  if mean > 0.5:\n",
        "    submission.loc[k,'target'] = 1\n",
        "    submission.loc[similar_test[k],'target'] = 1\n",
        "  else:\n",
        "    submission.loc[k,'target'] = 0\n",
        "    submission.loc[similar_test[k],'target'] = 0\n",
        "\n",
        "submission.to_csv('2_svc_submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUnS8LPMqMbu",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cz9eNyfY9Fi",
        "colab_type": "text"
      },
      "source": [
        "# 5. Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swt051QqHvCA",
        "colab_type": "code",
        "outputId": "6d5e4b56-72c4-4f72-ad70-d19166103325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.85)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbxzUJOfVP4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import SimpleRNN, GlobalAveragePooling1D, GlobalMaxPooling1D, Dropout, Embedding, Dense, Bidirectional, LSTM, Input\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import sentencepiece\n",
        "import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag9m6WU57T-I",
        "colab_type": "text"
      },
      "source": [
        "### Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvE2eDWK4IPz",
        "colab_type": "code",
        "outputId": "0c9a1258-9dbe-46b9-8c7e-6c7c81a7afbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X, y = train['text'], train['target'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    analyzer='word',\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 3),\n",
        "    lowercase=True,\n",
        "    min_df=5,\n",
        "    max_features=30000)\n",
        "\n",
        "char_vectorizer = TfidfVectorizer(\n",
        "    analyzer='char',\n",
        "    stop_words='english',\n",
        "    ngram_range=(3, 6),\n",
        "    lowercase=True,\n",
        "    min_df=5,\n",
        "    max_features=50000)\n",
        "\n",
        "vectorizer = FeatureUnion([('word_vectorizer', word_vectorizer),  ('char_vectorizer', char_vectorizer)])\n",
        "vectorizer.fit(X_train)\n",
        "\n",
        "X_train_vectors = vectorizer.transform(X_train).toarray()\n",
        "X_test_vectors = vectorizer.transform(X_test).toarray()\n",
        "print(X_train_vectors.shape, X_test_vectors.shape)\n",
        "\n",
        "X_train_text = X_train.tolist()\n",
        "X_test_text = X_test.tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5473, 52512) (1369, 52512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0y-BUSzVxw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOR8tyS-Vyyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-6wDmXExmlr",
        "colab_type": "code",
        "outputId": "fb2f9a7e-2c0e-46db-b80a-d0ac418a64ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "es = EarlyStopping(patience = 3, monitor='val_loss')\n",
        "nn_checkpoint = ModelCheckpoint('model_perceptron.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "history = model.fit(\n",
        "    x=X_train_vectors, y=y_train, batch_size=1024, epochs=10, verbose=True,\n",
        "    validation_data=(X_test_vectors, y_test), shuffle=True, callbacks = [es, nn_checkpoint]\n",
        ")\n",
        "\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5473 samples, validate on 1369 samples\n",
            "Epoch 1/10\n",
            "5473/5473 [==============================] - 2s 372us/sample - loss: 0.6799 - accuracy: 0.6850 - val_loss: 0.6384 - val_accuracy: 0.7852\n",
            "Epoch 2/10\n",
            "5473/5473 [==============================] - 2s 298us/sample - loss: 0.5784 - accuracy: 0.8551 - val_loss: 0.5374 - val_accuracy: 0.7977\n",
            "Epoch 3/10\n",
            "5473/5473 [==============================] - 2s 292us/sample - loss: 0.4218 - accuracy: 0.8891 - val_loss: 0.4591 - val_accuracy: 0.8013\n",
            "Epoch 4/10\n",
            "5473/5473 [==============================] - 1s 238us/sample - loss: 0.2810 - accuracy: 0.9143 - val_loss: 0.4713 - val_accuracy: 0.7911\n",
            "Epoch 5/10\n",
            "5473/5473 [==============================] - 1s 222us/sample - loss: 0.1860 - accuracy: 0.9421 - val_loss: 0.5325 - val_accuracy: 0.7809\n",
            "Epoch 6/10\n",
            "5473/5473 [==============================] - 1s 217us/sample - loss: 0.1141 - accuracy: 0.9715 - val_loss: 0.6162 - val_accuracy: 0.7750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hGP09saAqcBW"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu-c08pSx1D2",
        "colab_type": "text"
      },
      "source": [
        "### RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9_I3XWCG1ux",
        "colab_type": "text"
      },
      "source": [
        "This section is meant mainly for experimentation. It does not need to be considered for the deliverable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td1SQyYQ1R2y",
        "colab_type": "text"
      },
      "source": [
        "#### Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4heYLNHkFvsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features=50000\n",
        "maxlen=25\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(X_train.tolist())\n",
        "X_train = tokenizer.texts_to_sequences(X_train.tolist())\n",
        "X_test = tokenizer.texts_to_sequences(X_test.tolist())\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDX0O8X8yi-w",
        "colab_type": "code",
        "outputId": "28d1eaa6-4a67-42cc-8438-2695eff621fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_dim = X_train.max() + 1\n",
        "embed_dim = int(np.sqrt(vocab_dim))\n",
        "\n",
        "print(vocab_dim, embed_dim)\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_dim, output_dim=embed_dim),\n",
        "    SimpleRNN(units=embed_dim, return_sequences=False),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18753 136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpa7XWsrymIE",
        "colab_type": "code",
        "outputId": "81e4af03-ba7e-4d66-e562-aa8577f4ab90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "history = model.fit(\n",
        "    x=X_train, y=y_train, batch_size=64, epochs=5, verbose=True, validation_data=(X_test, y_test), shuffle=True\n",
        ")\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5473 samples, validate on 1369 samples\n",
            "Epoch 1/5\n",
            "5473/5473 [==============================] - 4s 701us/sample - loss: 0.6233 - accuracy: 0.6549 - val_loss: 0.5344 - val_accuracy: 0.7560\n",
            "Epoch 2/5\n",
            "5473/5473 [==============================] - 3s 553us/sample - loss: 0.2103 - accuracy: 0.9260 - val_loss: 0.5744 - val_accuracy: 0.7370\n",
            "Epoch 3/5\n",
            "5473/5473 [==============================] - 3s 553us/sample - loss: 0.0418 - accuracy: 0.9890 - val_loss: 0.6547 - val_accuracy: 0.7327\n",
            "Epoch 4/5\n",
            "5473/5473 [==============================] - 3s 547us/sample - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.7932 - val_accuracy: 0.7246\n",
            "Epoch 5/5\n",
            "5473/5473 [==============================] - 3s 550us/sample - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.8274 - val_accuracy: 0.6947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN3pLxraynVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_dim, output_dim=embed_dim),\n",
        "    SimpleRNN(units=embed_dim, return_sequences=True),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c5dRH_h1WJf",
        "colab_type": "code",
        "outputId": "e79f3b53-7884-4ae4-887f-db2c59a77299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "es = EarlyStopping(patience = 3, monitor='val_loss')\n",
        "simple_rnn_checkpoint = ModelCheckpoint('model_simple_rnn.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "history = model.fit(\n",
        "    x=X_train, y=y_train, batch_size=64, epochs=5, verbose=True,\n",
        "    validation_data=(X_test, y_test), shuffle=True, callbacks = [es, simple_rnn_checkpoint]\n",
        ")\n",
        "\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5473 samples, validate on 1369 samples\n",
            "Epoch 1/5\n",
            "5473/5473 [==============================] - 4s 714us/sample - loss: 0.6542 - accuracy: 0.6201 - val_loss: 0.6125 - val_accuracy: 0.6706\n",
            "Epoch 2/5\n",
            "5473/5473 [==============================] - 3s 567us/sample - loss: 0.4483 - accuracy: 0.8122 - val_loss: 0.4690 - val_accuracy: 0.7889\n",
            "Epoch 3/5\n",
            "5473/5473 [==============================] - 3s 558us/sample - loss: 0.1893 - accuracy: 0.9342 - val_loss: 0.4999 - val_accuracy: 0.7831\n",
            "Epoch 4/5\n",
            "5473/5473 [==============================] - 3s 549us/sample - loss: 0.0782 - accuracy: 0.9766 - val_loss: 0.5413 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "5473/5473 [==============================] - 3s 547us/sample - loss: 0.0356 - accuracy: 0.9907 - val_loss: 0.6698 - val_accuracy: 0.7641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJd2dJa31YCq",
        "colab_type": "text"
      },
      "source": [
        "#### Bidirectional RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q24gj7H71ahl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_dim, output_dim=embed_dim),\n",
        "    Bidirectional(SimpleRNN(units=embed_dim, return_sequences=True)),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMBWpgFB1cgX",
        "colab_type": "code",
        "outputId": "10c9c0f8-6cb5-4f59-acb4-9b49c1c05f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "es = EarlyStopping(patience = 3, monitor='val_loss')\n",
        "bi_rnn_checkpoint = ModelCheckpoint('model_bi_rnn.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "history = model.fit(\n",
        "    x=X_train, y=y_train, batch_size=64, epochs=5, verbose=True,\n",
        "    validation_data=(X_test, y_test), shuffle=True, callbacks = [es, bi_rnn_checkpoint]\n",
        ")\n",
        "\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5473 samples, validate on 1369 samples\n",
            "Epoch 1/5\n",
            "5473/5473 [==============================] - 6s 1ms/sample - loss: 0.6146 - accuracy: 0.6572 - val_loss: 0.5146 - val_accuracy: 0.7714\n",
            "Epoch 2/5\n",
            "5473/5473 [==============================] - 4s 757us/sample - loss: 0.3071 - accuracy: 0.8798 - val_loss: 0.5110 - val_accuracy: 0.7553\n",
            "Epoch 3/5\n",
            "5473/5473 [==============================] - 4s 759us/sample - loss: 0.1223 - accuracy: 0.9587 - val_loss: 0.7488 - val_accuracy: 0.7115\n",
            "Epoch 4/5\n",
            "5473/5473 [==============================] - 4s 750us/sample - loss: 0.0497 - accuracy: 0.9843 - val_loss: 0.8470 - val_accuracy: 0.7421\n",
            "Epoch 5/5\n",
            "5473/5473 [==============================] - 4s 759us/sample - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.9992 - val_accuracy: 0.7180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URvYe_He1csE",
        "colab_type": "text"
      },
      "source": [
        "#### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnxsKGz51cpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_dim, output_dim=embed_dim),\n",
        "    LSTM(units=embed_dim, return_sequences=False),\n",
        "    LSTM(units=embed_dim, return_sequences=False),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPOgqvxSGNwB",
        "colab_type": "code",
        "outputId": "963235f0-dd0d-4a29-bab0-00c58033e4e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 136)         2550408   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 136)               148512    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 137       \n",
            "=================================================================\n",
            "Total params: 2,699,057\n",
            "Trainable params: 2,699,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM5YHlXr1cmy",
        "colab_type": "code",
        "outputId": "22eb6018-b4bc-4634-a3ba-eb8a444156f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "es = EarlyStopping(patience = 3, monitor='val_loss')\n",
        "lstm_checkpoint = ModelCheckpoint('model_lstm_rnn.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "history = model.fit(\n",
        "    x=X_train, y=y_train, batch_size=64, epochs=10, verbose=True,\n",
        "    validation_data=(X_test, y_test), shuffle=True, callbacks = [es, lstm_checkpoint]\n",
        ")\n",
        "\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5473 samples, validate on 1369 samples\n",
            "Epoch 1/10\n",
            "5473/5473 [==============================] - 4s 706us/sample - loss: 0.5722 - accuracy: 0.6974 - val_loss: 0.4858 - val_accuracy: 0.7874\n",
            "Epoch 2/10\n",
            "5473/5473 [==============================] - 2s 384us/sample - loss: 0.2859 - accuracy: 0.8895 - val_loss: 0.4926 - val_accuracy: 0.7984\n",
            "Epoch 3/10\n",
            "5473/5473 [==============================] - 2s 373us/sample - loss: 0.1088 - accuracy: 0.9618 - val_loss: 0.7094 - val_accuracy: 0.7750\n",
            "Epoch 4/10\n",
            "5473/5473 [==============================] - 2s 375us/sample - loss: 0.0378 - accuracy: 0.9892 - val_loss: 0.7240 - val_accuracy: 0.7670\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUCiC0SqqeBs",
        "colab_type": "text"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQsEIVZw1kss",
        "colab_type": "text"
      },
      "source": [
        "### Transformer Encoder  BERT "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcxfAH6Qanut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def build_model(bert_layer, max_len=512):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    out = Dense(1, activation='sigmoid')(clf_output)\n",
        "    \n",
        "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(Adam(lr=6e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiklsEV1apHu",
        "colab_type": "code",
        "outputId": "1465111c-0c0e-421c-fc27-1d931013ea23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 19.6 s, sys: 4.36 s, total: 24 s\n",
            "Wall time: 34.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqtcICZqazoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17G3P_7ia01U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input = bert_encode(train.text.values, tokenizer, max_len=160)\n",
        "test_input = bert_encode(test.text.values, tokenizer, max_len=160)\n",
        "train_labels = train.target.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFdHNQ-6a19I",
        "colab_type": "code",
        "outputId": "1da0c24b-7a95-4fbe-be8c-58b3553d8e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model = build_model(bert_layer, max_len=160)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 1024)]       0           keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            1025        tf_op_layer_strided_slice[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 335,142,914\n",
            "Trainable params: 335,142,913\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmpJ6uB1bptS",
        "colab_type": "code",
        "outputId": "7260c2e2-6b4e-408c-8da4-b45bad85702e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "es = EarlyStopping(patience = 3, restore_best_weights = True)\n",
        "checkpoint = ModelCheckpoint('model_BERT.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "train_history = model.fit(\n",
        "    train_input, train_labels,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    callbacks = [es, checkpoint]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5473 samples, validate on 1369 samples\n",
            "Epoch 1/10\n",
            "5473/5473 [==============================] - 445s 81ms/sample - loss: 0.4416 - accuracy: 0.8091 - val_loss: 0.3972 - val_accuracy: 0.8305\n",
            "Epoch 2/10\n",
            "5473/5473 [==============================] - 338s 62ms/sample - loss: 0.2673 - accuracy: 0.8969 - val_loss: 0.4581 - val_accuracy: 0.8232\n",
            "Epoch 3/10\n",
            "5473/5473 [==============================] - 337s 62ms/sample - loss: 0.0956 - accuracy: 0.9671 - val_loss: 0.6233 - val_accuracy: 0.8064\n",
            "Epoch 4/10\n",
            "5473/5473 [==============================] - 338s 62ms/sample - loss: 0.0356 - accuracy: 0.9905 - val_loss: 0.7522 - val_accuracy: 0.8137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK7nP9T2S8H8",
        "colab_type": "code",
        "outputId": "67810769-1ec4-4ad3-ae38-76da6a877665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "# f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 4))\n",
        "f, (ax1, ax3) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('Basic Multi-Layered Perceptron Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(len(train_history.history['loss'])))\n",
        "ax1.plot(epoch_list, train_history.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, train_history.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "# ax2.plot(epoch_list, train_history.history['f1_m'], label='Train F1 Score')\n",
        "# ax2.plot(epoch_list, train_history.history['val_f1_m'], label='Validation F1 Score')\n",
        "# ax2.set_ylabel('F1 Score Value')\n",
        "# ax2.set_xlabel('Epoch')\n",
        "# ax2.set_title('F1 Score')\n",
        "# l2 = ax2.legend(loc=\"best\")\n",
        "\n",
        "ax3.plot(epoch_list, train_history.history['loss'], label='Train Loss')\n",
        "ax3.plot(epoch_list, train_history.history['val_loss'], label='Validation Loss')\n",
        "ax3.set_ylabel('Loss Value')\n",
        "ax3.set_xlabel('Epoch')\n",
        "ax3.set_title('Loss')\n",
        "l3 = ax3.legend(loc=\"best\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyT7DefpbrLC",
        "colab_type": "code",
        "outputId": "0846a1f7-f02f-4552-80f3-3ab930f2d773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "bert_preds = model.predict(train_input)\n",
        "\n",
        "print(classification_report(train_labels, bert_preds.round().astype(int)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.95      0.91      4097\n",
            "         1.0       0.91      0.79      0.84      2745\n",
            "\n",
            "    accuracy                           0.88      6842\n",
            "   macro avg       0.89      0.87      0.87      6842\n",
            "weighted avg       0.88      0.88      0.88      6842\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUzcP-2-4XYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = model.predict(test_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PX4xXbA4cts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission['target'] = test_pred.round().astype(int)\n",
        "\n",
        "for k in similar_test.keys():\n",
        "  summation = submission.loc[similar_test[k],:]['target'].sum() + submission.loc[k,:]['target']\n",
        "  count = len(similar[k]) + 1\n",
        "  mean = summation/count\n",
        "  if mean > 0.5:\n",
        "    submission.loc[k,'target'] = 1\n",
        "    submission.loc[similar_test[k],'target'] = 1\n",
        "  else:\n",
        "    submission.loc[k,'target'] = 0\n",
        "    submission.loc[similar_test[k],'target'] = 0\n",
        "\n",
        "submission.to_csv('2_bert_submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwgmJIrxPz1I",
        "colab_type": "text"
      },
      "source": [
        "**KAGGLE SCORE:** 0.83946"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STaF42MrRJ6p",
        "colab_type": "text"
      },
      "source": [
        "Lastly, we will try and combine the predictions of the BERT model with the two previously strongest models, which produced `lr_pred` and `svc_pred`. The results are not likely to be as strong as the BERT model alone, but it's worth a try."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJlD6PnbQCxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stack_pred_2 = []\n",
        "\n",
        "for i in range(len(lr_pred)):\n",
        "  if (lr_pred[i] + test_pred[i] + svc_pred[i]) >= 2:\n",
        "    stack_pred_2.append(1)\n",
        "  else:\n",
        "    stack_pred_2.append(0)\n",
        "    \n",
        "\n",
        "submission['target'] = stack_pred_2\n",
        "\n",
        "for k in similar_test.keys():\n",
        "  summation = submission.loc[similar_test[k],:]['target'].sum() + submission.loc[k,:]['target']\n",
        "  count = len(similar[k]) + 1\n",
        "  mean = summation/count\n",
        "  if mean > 0.5:\n",
        "    submission.loc[k,'target'] = 1\n",
        "    submission.loc[similar_test[k],'target'] = 1\n",
        "  else:\n",
        "    submission.loc[k,'target'] = 0\n",
        "    submission.loc[similar_test[k],'target'] = 0\n",
        "\n",
        "submission.to_csv('2_stacked_submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxcMk5caRJbQ",
        "colab_type": "text"
      },
      "source": [
        "**KAGGLE SCORE:** 0.83231\n",
        "\n",
        "As expected, the introduction of the two weaker models hindered performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP6NFcIH4mxf",
        "colab_type": "text"
      },
      "source": [
        "# 6. Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zYPbzq5JrDG",
        "colab_type": "text"
      },
      "source": [
        "## Reflection\n",
        "\n",
        "The results I achieved throughout this process were very surprising. After dozens of hours of experimentation, a fragment of which can be seen here, the best results proved to have come from some very simple pre-processing.\n",
        "\n",
        "<br>\n",
        "\n",
        "When I initially began modelling, I had not dealt with duplicates and I was using a simple Tfidf Vectorizer. When doing so, my initial baseline results were relatively poor. As a result, many of the iterative cleaning steps improved the model substantially. Many of the cleaning steps were being accepted by the `try_step()` function and my models were improving by rougly 5 percentage points from the baseline throughout the cleaning process. However, they remained in the high-70s.\n",
        "\n",
        "<br>\n",
        "\n",
        "However, after taking a closer look at the data and dealing with duplicates and putting Google's universal encoder to use, the baseline models shot up. The stacked model, which achieved 81%+ f1-score on Kaggle, was 3+ percentage points better than the cleaned and optimized non-deep learning models I had trained before.\n",
        "\n",
        "<br>\n",
        "\n",
        "Ultimately, of the models scored on Kaggle, BERT proved to be the best, which was to be expected. However, the difference between the BERT results and the result of the stacked baseline is not immense. Though with more time, the results of the BERT model could likely be improved from the ~84% that was achieved, it's not clear that the complexity of the model is warranted given the performance of the simpler models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm9th5kNqjBI",
        "colab_type": "text"
      },
      "source": [
        "## Recommendations\n",
        "\n",
        "The recommendation for users of the models created above is to opt for the simplicity of the ensembled approach using simple algorithms, such as **logistic regress** and **naive bayes**. Given that performance is quite good if cleaning is done with some amount of diligence, the simpler models are a good option. More complex models, though powerful in their own right, introduce unwarranted overhead and complexity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "605EmKNiqn_P",
        "colab_type": "text"
      },
      "source": [
        "## Opportunities for Improvement\n",
        "\n",
        "Other steps that may have been worthwhile to experiment include dependency parsing and n-grams. However, the reason for not using them is that nature of tweets is that they are not easily cleaned so as to be used effectively alongside a parser. With that said, with more time, the appropriate cleaning could have been done to make those tools effective."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtz1bQTpM6Gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/file.zip /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90JjvV7WM8pG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}